{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Dummy Data\n",
    "\n",
    "Generate data according to $y = x_1 + 2x_2 + 3x_3$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+------------------+------------------+------------------+\n",
      "|                x1|                x2|                x3|                 y|\n",
      "+------------------+------------------+------------------+------------------+\n",
      "|  64.4817542443203|  64.9836020835302| 42.69495350096511|  322.533818914276|\n",
      "|  79.6847253074154| 42.24299337729658|24.270577087512045| 236.9824433245447|\n",
      "| 96.19210956565894| 47.67103248508631|  34.3704759118884| 294.6456022714967|\n",
      "| 73.64834716438214| 33.55295811971977|14.885980608569572| 185.4122052295304|\n",
      "| 90.52472359657864| 56.01089283416708| 74.75058796401082|426.79827315694524|\n",
      "| 32.88804555707674| 68.33729286349431| 44.35036380289458| 302.6137226927491|\n",
      "|18.372687963745683| 95.33755341720891|  15.7354010856253| 256.2539980550394|\n",
      "| 80.66991985399748|  38.0787423257596| 40.14828039937336|277.27224570363677|\n",
      "| 98.70467443622748|   7.4301428466089| 81.07031801233549|356.77591416645174|\n",
      "| 16.58016823391368| 97.13707824345154| 46.03651140560293|348.96385893762556|\n",
      "| 30.91884534526379| 64.99350797908224| 43.46191703742337|291.29161241569835|\n",
      "| 92.20735565576756|    56.95849326647| 92.62943373494011|484.01264339352787|\n",
      "|  71.4335600957534| 79.01886240930273|22.940085349501217|298.29154096286254|\n",
      "| 80.05115620357284| 75.75033818292411| 5.005622606152638|246.56870038787898|\n",
      "| 68.75526351165277|19.774841280053824| 57.10481917536608|279.61940359785865|\n",
      "| 36.90231529267184|10.778369886277128| 71.13860951662917| 271.8748836151136|\n",
      "| 41.81647589285647| 74.44413331454007|28.736814771284347|276.91518683578965|\n",
      "|13.602644892676551| 20.37351335072808| 8.100567581880592| 78.65137433977449|\n",
      "| 20.00900315092987| 94.44294376195856|45.011439545204645| 343.9292093104609|\n",
      "| 9.699228412032268| 5.862110116372676| 96.19573859120557|310.01066441839436|\n",
      "+------------------+------------------+------------------+------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import scala.math._\n",
    "val sqlContext = org.apache.spark.sql.SQLContext.getOrCreate(sc)\n",
    "import sqlContext.implicits._\n",
    "\n",
    "\n",
    "// gen data according to x1 + \n",
    "def genRanRow: (Double, Double, Double, Double) = {\n",
    "    val (x1, x2, x3) = (100*random, 100*random, 100*random)\n",
    "    (x1, x2, x3, x1 + 2*x2 + 3*x3)\n",
    "}\n",
    "\n",
    "val myDF = sc.parallelize((0 to 10000).map(x => genRanRow)).toDF(\"x1\", \"x2\", \"x3\", \"y\")\n",
    "\n",
    "myDF.show"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run Linear Regression\n",
    "\n",
    "Here are the steps to running linear regression:\n",
    "\n",
    "1. Split the data into training and testing sets\n",
    "- Make a `VectorAssembler` which combines our feature columns into a single `features` column\n",
    "- Make a `LinearRegression` object with label column `y`\n",
    "- Put the `VectorAssembler` and `LinearRegression` objects into a single `Pipeline` object\n",
    "- Fit the `Pipeline` to the training data. This runs the `VectorAssembler` and the `LinearRegression`\n",
    "- Tranform the testing data with our `Pipeline` to make predictions. This runs the `VectorAssembler` and applies the learned `LinearRegression` method\n",
    "- Extract the `LinearRegressionModel` from our `Pipeline` to check the Root Mean Square Error = $\\displaystyle\\sqrt{\\displaystyle\\frac{\\sum_i (x_i - \\hat{x_i})^2}{n}}$ and the coffificients $x_1$, $x_2$, and $x_3$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 4.3049474205807575E-13\n",
      "[0.999999999999993,2.0000000000000053,2.999999999999988]\n"
     ]
    }
   ],
   "source": [
    "/* Import needed classes*/\n",
    "import org.apache.spark.ml.feature.VectorAssembler\n",
    "import org.apache.spark.ml.regression.{LinearRegression, LinearRegressionModel}\n",
    "import org.apache.spark.ml.Pipeline\n",
    "\n",
    "/* (1) Split the Data */\n",
    "val Array(trainingData, testData) = myDF.randomSplit(Array(0.7, 0.3))\n",
    "\n",
    "/* (2) Make your feature vector assembler */\n",
    "val assembler = new VectorAssembler().\n",
    "    setInputCols(Array(\"x1\", \"x2\", \"x3\")).\n",
    "    setOutputCol(\"features\")\n",
    "\n",
    "/* (3) Make your Linear Regression model */\n",
    "val lr = new LinearRegression().setLabelCol(\"y\")\n",
    "\n",
    "/* (4) Put the assembler and regression model into a pipeline */\n",
    "val pipeline = new Pipeline().setStages(Array(assembler, lr))\n",
    "\n",
    "/* (5) Run the pipeline on your training data */\n",
    "val model = pipeline.fit(trainingData)\n",
    "\n",
    "/* (6) Make the predictions */\n",
    "val predictions = model.transform(testData).persist\n",
    "\n",
    "/* (7) Pull out the linear regression model from the pipeline, generate summary info */\n",
    "val lrModel = model.stages(1).asInstanceOf[LinearRegressionModel]\n",
    "val trainingSummary = lrModel.summary\n",
    "\n",
    "/* (7.1) Print the Root Mean Square Error */\n",
    "println(s\"RMSE: ${trainingSummary.rootMeanSquaredError}\")\n",
    "\n",
    "/* (7.2) Print the Coefficients */\n",
    "println(lrModel.coefficients)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "As we can see the model found the correct coefficients (within a very small $\\varepsilon$) with a corresponding error of $4.3 \\times 10^{-13}$"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Apache Toree - Scala",
   "language": "scala",
   "name": "apache_toree_scala"
  },
  "language_info": {
   "name": "scala",
   "version": "2.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
