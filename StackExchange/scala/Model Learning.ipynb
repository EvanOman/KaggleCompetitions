{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "/* Add Deps */\n",
    "%AddDeps edu.stanford.nlp stanford-corenlp 3.7.0\n",
    "%AddDeps com.google.protobuf protobuf-java 2.6.1\n",
    "%AddDeps com.databricks spark-csv_2.10 1.5.0 --transitive\n",
    "\n",
    "// Non-repo dependencies \n",
    "%AddJar file:lib/corenlp-models.jar\n",
    "%AddJar file:SE/target/scala-2.10/se_2.10-1.1.jar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import com.evan.kaggle.se.FeatureEngineering._\n",
    "val sqlContext = org.apache.spark.sql.SQLContext.getOrCreate(sc)\n",
    "import sqlContext.implicits._\n",
    "import org.apache.spark.sql.functions._\n",
    "import org.apache.spark.sql.Row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "val files = List(\"cooking\", \"crypto\", \"robotics\", \"biology\", \"travel\", \"diy\")\n",
    "\n",
    "/* Load and print all files */\n",
    "val df_all = files.map(f => {\n",
    "                        sqlContext.read.format(\"com.databricks.spark.csv\").option(\"header\", \"true\").load(\"../dat/\"+f+\"_clean.csv\")\n",
    "                   }).reduce(_ unionAll _).withColumn(\"tags\", split($\"tags\", \" \"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_all.show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "val rdd = df_all.select(\"title\", \"content\").rdd.map{case Row(t: String, c: String) => (t, c)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "val twoGramFeats = makeStdFeatures(2) _\n",
    "val featDF = rdd.flatMap(x => twoGramFeats(x._1, x._2)).toDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "featDF.show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "featDF.count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Apache Toree - Scala",
   "language": "scala",
   "name": "apache_toree_scala"
  },
  "language_info": {
   "name": "scala",
   "version": "2.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
