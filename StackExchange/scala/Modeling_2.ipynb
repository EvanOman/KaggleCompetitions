{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Marking edu.stanford.nlp:stanford-corenlp:3.7.0 for download\n",
      "Preparing to fetch from:\n",
      "-> file:/tmp/toree_add_deps2551422517658262765/\n",
      "-> https://repo1.maven.org/maven2\n",
      "-> New file at /tmp/toree_add_deps2551422517658262765/https/repo1.maven.org/maven2/edu/stanford/nlp/stanford-corenlp/3.7.0/stanford-corenlp-3.7.0.jar\n",
      "Marking com.google.protobuf:protobuf-java:2.6.1 for download\n",
      "Preparing to fetch from:\n",
      "-> file:/tmp/toree_add_deps2551422517658262765/\n",
      "-> https://repo1.maven.org/maven2\n",
      "-> New file at /tmp/toree_add_deps2551422517658262765/https/repo1.maven.org/maven2/com/google/protobuf/protobuf-java/2.6.1/protobuf-java-2.6.1.jar\n",
      "Marking com.databricks:spark-csv_2.10:1.5.0 for download\n",
      "Preparing to fetch from:\n",
      "-> file:/tmp/toree_add_deps2551422517658262765/\n",
      "-> https://repo1.maven.org/maven2\n",
      "-> New file at /tmp/toree_add_deps2551422517658262765/https/repo1.maven.org/maven2/org/apache/commons/commons-csv/1.1/commons-csv-1.1.jar\n",
      "-> New file at /tmp/toree_add_deps2551422517658262765/https/repo1.maven.org/maven2/com/databricks/spark-csv_2.10/1.5.0/spark-csv_2.10-1.5.0.jar\n",
      "-> New file at /tmp/toree_add_deps2551422517658262765/https/repo1.maven.org/maven2/com/univocity/univocity-parsers/1.5.1/univocity-parsers-1.5.1.jar\n",
      "Starting download from file:lib/corenlp-models.jar\n",
      "Finished download of corenlp-models.jar\n",
      "Starting download from file:SE/target/scala-2.10/se_2.10-1.1.jar\n",
      "Finished download of se_2.10-1.1.jar\n"
     ]
    }
   ],
   "source": [
    "/* Add Deps */\n",
    "%AddDeps edu.stanford.nlp stanford-corenlp 3.7.0\n",
    "%AddDeps com.google.protobuf protobuf-java 2.6.1\n",
    "%AddDeps com.databricks spark-csv_2.10 1.5.0 --transitive\n",
    "\n",
    "// Non-repo dependencies \n",
    "%AddJar file:lib/corenlp-models.jar\n",
    "%AddJar file:SE/target/scala-2.10/se_2.10-1.1.jar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import com.evan.kaggle.se.FeatureEngineering._\n",
    "val sqlContext = org.apache.spark.sql.SQLContext.getOrCreate(sc)\n",
    "import sqlContext.implicits._\n",
    "import org.apache.spark.sql.functions._\n",
    "import org.apache.spark.sql.Row\n",
    "import scala.collection.immutable.HashSet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "val files = List(\"cooking\")//, \"crypto\", \"robotics\", \"biology\", \"travel\", \"diy\")\n",
    "\n",
    "/* Load and print all files */\n",
    "val df_all = files.map(f => {\n",
    "                        sqlContext.read.format(\"com.databricks.spark.csv\").option(\"header\", \"true\").load(\"../dat/\"+f+\"_clean.csv\")\n",
    "                   }).reduce(_ unionAll _)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "val clean_udf = udf( (s:String) => s.replaceAll(\"[^\\\\p{ASCII}]+\", \"\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "val mkFeat_UDF = udf((t: String, c: String, ta: String) => makeTrFeatures(5)(t, c, ta))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "val featDF = df_all.select(explode(mkFeat_UDF($\"title\", $\"content\", $\"tags\")))\n",
    "val featDF2 = featDF.select(\"col.*\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-------+---------+------------------+--------+--------+-------+-----+\n",
      "|    nGram|posTags|  depTags|            relPos|numWords|hasUpper|isTitle|isTag|\n",
      "+---------+-------+---------+------------------+--------+--------+-------+-----+\n",
      "|      <p>|     NN| compound|               0.0|       1|   false|  false|false|\n",
      "|       my|   PRP$|nmod:poss|0.1111111111111111|       1|    true|  false|false|\n",
      "|chocolate|     NN| compound|0.2222222222222222|       1|   false|  false|false|\n",
      "|     chip|    NNS| compound|0.3333333333333333|       1|   false|  false|false|\n",
      "|   cookie|    NNS|    nsubj|0.4444444444444444|       1|   false|  false| true|\n",
      "|       be|    VBP|      cop|0.5555555555555556|       1|   false|  false|false|\n",
      "|   always|     RB|   advmod|0.6666666666666666|       1|   false|  false|false|\n",
      "|      too|     RB|   advmod|0.7777777777777778|       1|   false|  false|false|\n",
      "|    crisp|     JJ|     root|0.8888888888888888|       1|   false|  false|false|\n",
      "|      how|    WRB|   advmod|               0.0|       1|    true|  false|false|\n",
      "|      can|     MD|      aux|               0.1|       1|   false|  false|false|\n",
      "|        I|    PRP|    nsubj|               0.2|       1|    true|  false|false|\n",
      "|      get|     VB|     root|               0.3|       1|   false|  false|false|\n",
      "|    chewy|     JJ|     amod|               0.4|       1|   false|  false|false|\n",
      "|   cookie|    NNS|     dobj|               0.5|       1|   false|  false| true|\n",
      "|     like|     IN|     case|               0.6|       1|   false|  false|false|\n",
      "|    those|     DT|nmod:like|               0.7|       1|   false|  false|false|\n",
      "|       of|     IN|     case|               0.8|       1|   false|  false|false|\n",
      "|Starbucks|    NNP|  nmod:of|               0.9|       1|    true|  false|false|\n",
      "|     </p>|     JJ|     amod|               0.0|       1|   false|  false|false|\n",
      "+---------+-------+---------+------------------+--------+--------+-------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "featDF2.show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7183278"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "featDF2.count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Name: Compile Error\n",
       "Message: <console>:1: error: unclosed string literal\n",
       "       featDF2.wite.save(\"mypar.parquet)\n",
       "                         ^\n",
       "StackTrace: "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "featDF2.wite.save(\"mypar.parquet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "val sub = trainingDF.sample(false, .001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "val replace_dash = udf( (s:String) => s.replaceAll(\"-\", \" \"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "val data = sub.withColumn(\"posTags\", replace_dash($\"posTags\")).\n",
    "    withColumn(\"depTags\", replace_dash($\"depTags\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [],
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import org.apache.spark.ml.Pipeline\n",
    "import org.apache.spark.ml.classification.{RandomForestClassificationModel, RandomForestClassifier}\n",
    "import org.apache.spark.ml.evaluation.MulticlassClassificationEvaluator\n",
    "import org.apache.spark.ml.feature.{IndexToString, StringIndexer, VectorIndexer}\n",
    "import org.apache.spark.ml.feature.{HashingTF, IDF, Tokenizer}\n",
    "\n",
    "val tokenizer = new Tokenizer().setInputCol(\"posTags\").\n",
    "  setInputCol(\"depTags\").setOutputCol(\"tags\")\n",
    "val wordsData = tokenizer.transform(data)\n",
    "val hashingTF = new HashingTF().\n",
    "  setInputCol(\"tags\").setOutputCol(\"hashedTags\").setNumFeatures(20)\n",
    "val featurizedData = hashingTF.transform(wordsData)\n",
    "val idf = new IDF().setInputCol(\"hashedTags\").setOutputCol(\"idfTags\")\n",
    "val idfModel = idf.fit(featurizedData)\n",
    "val rescaledData = idfModel.transform(featurizedData)\n",
    "\n",
    "// Split the data into training and test sets (30% held out for testing)\n",
    "val Array(trainingData, testData) = data.randomSplit(Array(0.7, 0.3))\n",
    "\n",
    "// Train a RandomForest model.\n",
    "val rf = new RandomForestClassifier().\n",
    "  setLabelCol(\"isTag\").\n",
    "  setFeaturesCol(\"idfTags\").\n",
    "  .setNumTrees(10)\n",
    "\n",
    "// Chain indexers and forest in a Pipeline\n",
    "val pipeline = new Pipeline().\n",
    "setStages(Array(rescaledData, rf))\n",
    "\n",
    "// Train model.  This also runs the indexers.\n",
    "val model = pipeline.fit(trainingData)\n",
    "\n",
    "// Make predictions.\n",
    "val predictions = model.transform(testData)\n",
    "\n",
    "// Select example rows to display.\n",
    "predictions.select(\"predictedLabel\", \"label\", \"features\").show(5)\n",
    "\n",
    "// Select (prediction, true label) and compute test error\n",
    "val evaluator = new MulticlassClassificationEvaluator().\n",
    "setLabelCol(\"indexedLabel\").\n",
    "setPredictionCol(\"prediction\").\n",
    "setMetricName(\"precision\")\n",
    "val accuracy = evaluator.evaluate(predictions)\n",
    "println(\"Test Error = \" + (1.0 - accuracy))\n",
    "\n",
    "val rfModel = model.stages(2).asInstanceOf[RandomForestClassificationModel]\n",
    "println(\"Learned classification forest model:\\n\" + rfModel.toDebugString)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Apache Toree - Scala",
   "language": "scala",
   "name": "apache_toree_scala"
  },
  "language_info": {
   "name": "scala",
   "version": "2.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
