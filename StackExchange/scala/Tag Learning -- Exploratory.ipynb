{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Marking org.sameersingh.scalaplot:scalaplot:0.0.4 for download\n",
      "Preparing to fetch from:\n",
      "-> file:/tmp/toree_add_deps3630819211546819142/\n",
      "-> https://repo1.maven.org/maven2\n",
      "-> New file at /tmp/toree_add_deps3630819211546819142/https/repo1.maven.org/maven2/org/sameersingh/scalaplot/scalaplot/0.0.4/scalaplot-0.0.4.jar\n",
      "Marking com.google.protobuf:protobuf-java:2.6.1 for download\n",
      "Preparing to fetch from:\n",
      "-> file:/tmp/toree_add_deps3630819211546819142/\n",
      "-> https://repo1.maven.org/maven2\n",
      "-> New file at /tmp/toree_add_deps3630819211546819142/https/repo1.maven.org/maven2/com/google/protobuf/protobuf-java/2.6.1/protobuf-java-2.6.1.jar\n",
      "Marking com.databricks:spark-csv_2.10:1.5.0 for download\n",
      "Preparing to fetch from:\n",
      "-> file:/tmp/toree_add_deps3630819211546819142/\n",
      "-> https://repo1.maven.org/maven2\n",
      "-> New file at /tmp/toree_add_deps3630819211546819142/https/repo1.maven.org/maven2/com/univocity/univocity-parsers/1.5.1/univocity-parsers-1.5.1.jar\n",
      "-> New file at /tmp/toree_add_deps3630819211546819142/https/repo1.maven.org/maven2/com/databricks/spark-csv_2.10/1.5.0/spark-csv_2.10-1.5.0.jar\n",
      "-> New file at /tmp/toree_add_deps3630819211546819142/https/repo1.maven.org/maven2/org/apache/commons/commons-csv/1.1/commons-csv-1.1.jar\n"
     ]
    }
   ],
   "source": [
    "%AddDeps org.sameersingh.scalaplot scalaplot 0.0.4\n",
    "%AddDeps com.google.protobuf protobuf-java 2.6.1\n",
    "%AddDeps com.databricks spark-csv_2.10 1.5.0 --transitive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "val sqlContext = org.apache.spark.sql.SQLContext.getOrCreate(sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import sqlContext.implicits._\n",
    "import org.apache.spark.sql.functions._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preconditions\n",
    "- Make sure data has been downloaded with `download_data.py`\n",
    "- Make sure the first pass of cleaning has been performed with `clean_files.scala`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "val files = List(\"cooking\", \"crypto\", \"robotics\", \"biology\", \"travel\", \"diy\")\n",
    "\n",
    "/* Load and print all files */\n",
    "val df_all = files.map(f => {\n",
    "                        sqlContext.read.format(\"com.databricks.spark.csv\").option(\"header\", \"true\").load(\"../dat/\"+f+\"_clean.csv\")\n",
    "                   }).reduce(_ unionAll _).withColumn(\"tags\", split($\"tags\", \" \"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------------------+--------------------+--------------------+\n",
      "| id|               title|             content|                tags|\n",
      "+---+--------------------+--------------------+--------------------+\n",
      "|  1|How can I get che...| My chocolate chi...|[baking, cookies,...|\n",
      "|  2|How should I cook...| I've heard of pe...|[oven, cooking-ti...|\n",
      "|  3|What is the diffe...| I always use bro...|              [eggs]|\n",
      "|  4|What is the diffe...| And can I use on...|[substitutions, p...|\n",
      "|  5|In a tomato sauce...| It seems that ev...|[sauce, pasta, to...|\n",
      "|  6|What ingredients ...| I have a recipe ...|[substitutions, h...|\n",
      "|  9|What is the inter...| I'd like to know...|[food-safety, bee...|\n",
      "| 11|How should I poac...| What's the best ...|[eggs, basics, po...|\n",
      "| 12|How can I make my...| My ice cream doe...|         [ice-cream]|\n",
      "| 17|How long and at w...| I'm interested i...|[baking, chicken,...|\n",
      "| 23|Besides salmon, w...| I've fallen in l...|[grilling, salmon...|\n",
      "| 27|Do I need to sift...| Is there really ...|[baking, flour, m...|\n",
      "| 28|Storage life for ...| When I roast a g...|[storage-method, ...|\n",
      "| 30|Pressure canning ...| Where can safe a...|[canning, pressur...|\n",
      "| 32|What's a good res...| I know what spic...|[spices, resource...|\n",
      "| 36|Is it safe to lea...| Is it safe to le...|[food-safety, sto...|\n",
      "| 38|Does resting the ...| In this article ...|[baking, bread, d...|\n",
      "| 54|How should I prep...| I've been watchi...|[rice, italian-cu...|\n",
      "| 57|How does a splash...| What does splash...|[eggs, food-scien...|\n",
      "| 61|What are the pros...| Why should/shoul...|[storage-method, ...|\n",
      "+---+--------------------+--------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_all.show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "87000"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_all.count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import sqlContext.implicits._\n",
    "import org.apache.spark.sql.Row\n",
    "val rdd = df_all.select(\"tags\").rdd.map{case Row(t: Seq[String]) => t}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(meet-in-the-middle-attack,5)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val tags = rdd.collect.flatMap(_.map(t => (t, t.split(\"-\").size)))\n",
    "val tagsDF = tags.toSeq.distinct.toDF(\"tag\", \"length\")\n",
    "\n",
    "tags.maxBy(_._2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+------+\n",
      "|                 tag|length|\n",
      "+--------------------+------+\n",
      "|              baking|     1|\n",
      "|             cookies|     1|\n",
      "|             texture|     1|\n",
      "|                oven|     1|\n",
      "|        cooking-time|     2|\n",
      "|               bacon|     1|\n",
      "|                eggs|     1|\n",
      "|       substitutions|     1|\n",
      "|please-remove-thi...|     4|\n",
      "|         baking-soda|     2|\n",
      "|       baking-powder|     2|\n",
      "|               sauce|     1|\n",
      "|               pasta|     1|\n",
      "|            tomatoes|     1|\n",
      "|     italian-cuisine|     2|\n",
      "|               herbs|     1|\n",
      "|             parsley|     1|\n",
      "|         food-safety|     2|\n",
      "|                beef|     1|\n",
      "|              basics|     1|\n",
      "+--------------------+------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tagsDF.show"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TODO: load all data and do a histogram over tag lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------------+------+\n",
      "|tag                      |length|\n",
      "+-------------------------+------+\n",
      "|meet-in-the-middle-attack|5     |\n",
      "|san-francisco-bay-area   |4     |\n",
      "|change-purpose-of-travel |4     |\n",
      "|t-and-t-citizens         |4     |\n",
      "|90-180-visa-rules        |4     |\n",
      "|us-visa-waiver-program   |4     |\n",
      "|proof-of-onward-travel   |4     |\n",
      "|man-in-the-middle        |4     |\n",
      "|proof-provenance-of-funds|4     |\n",
      "|great-wall-of-china      |4     |\n",
      "|ho-chi-minh-city         |4     |\n",
      "|please-remove-this-tag   |4     |\n",
      "|gondolas-and-cable-cars  |4     |\n",
      "|half-and-half            |3     |\n",
      "|brute-force-attack       |3     |\n",
      "|middle-eastern-cuisine   |3     |\n",
      "|deep-dish-pizza          |3     |\n",
      "|cut-of-meat              |3     |\n",
      "|known-plaintext-attack   |3     |\n",
      "|side-channel-attack      |3     |\n",
      "+-------------------------+------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tagsDF.sort(-$\"length\").show(false)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import org.sameersingh.scalaplot.Implicits._\n",
    "val data = tags.map(_._2).groupBy(identity).mapValues(_.length)\n",
    "val (x, y) = data.toSeq.sortBy(_._1).map(x => (x._1.toDouble, x._2.toDouble)).unzip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Name: Compile Error\n",
       "Message: <console>:19: error: not found: value output\n",
       "              kernel.magics.html(output(SVG, barChart(x -> y)))\n",
       "                                 ^\n",
       "StackTrace: "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kernel.magics.html(output(SVG, barChart(x -> y)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Apache Toree - Scala",
   "language": "scala",
   "name": "apache_toree_scala"
  },
  "language_info": {
   "name": "scala",
   "version": "2.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
