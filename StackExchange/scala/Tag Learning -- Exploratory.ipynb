{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Marking org.sameersingh.scalaplot:scalaplot:0.0.4 for download\n",
      "Preparing to fetch from:\n",
      "-> file:/tmp/toree_add_deps1258866547526972494/\n",
      "-> https://repo1.maven.org/maven2\n",
      "-> New file at /tmp/toree_add_deps1258866547526972494/https/repo1.maven.org/maven2/org/sameersingh/scalaplot/scalaplot/0.0.4/scalaplot-0.0.4.jar\n"
     ]
    }
   ],
   "source": [
    "%AddDeps org.sameersingh.scalaplot scalaplot 0.0.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "val ss = org.apache.spark.sql.SparkSession.builder().getOrCreate()\n",
    "import ss.implicits._\n",
    "import org.apache.spark.sql.functions._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---+---------------+\n",
      "|        a|  b|              c|\n",
      "+---------+---+---------------+\n",
      "|      a a|  2|         [a, a]|\n",
      "|a a a a a|  4|[a, a, a, a, a]|\n",
      "+---------+---+---------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "val df = Seq((\"a a\",2),(\"a a a a a\",4)).toDF(\"a\", \"b\")\n",
    "df.withColumn(\"c\", split($\"a\", \" \")).show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+---+---+\n",
      "|    a|  b|  c|\n",
      "+-----+---+---+\n",
      "|   aa|  2|  2|\n",
      "|aaaaa|  4|  5|\n",
      "+-----+---+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.withColumn(\"c\", length($\"a\")).show"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preconditions\n",
    "- Make sure data has been downloaded with `download_data.py`\n",
    "- Make sure the first pass of cleaning has been performed with `clean_files.scala`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "// val ss = org.apache.spark.sql.SparkSession.builder().getOrCreate()\n",
    "// import ss.implicits._\n",
    "// import org.apache.spark.sql.functions._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "val files = List(\"cooking\", \"crypto\", \"robotics\", \"biology\", \"travel\", \"diy\")\n",
    "\n",
    "/* Load and print all files */\n",
    "val df_all = files.map(f => {\n",
    "                        ss.read.format(\"csv\").option(\"header\", \"true\").load(\"../dat/\"+f+\"_clean.csv\")\n",
    "                   }).reduce(_ union _).withColumn(\"tags\", split($\"tags\", \" \"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------------------+--------------------+--------------------+\n",
      "| id|               title|             content|                tags|\n",
      "+---+--------------------+--------------------+--------------------+\n",
      "|  1|How can I get che...|<p>My chocolate c...|[baking, cookies,...|\n",
      "|  2|How should I cook...|<p>I've heard of ...|[oven, cooking-ti...|\n",
      "|  3|What is the diffe...|<p>I always use b...|              [eggs]|\n",
      "|  4|What is the diffe...|<p>And can I use ...|[substitutions, p...|\n",
      "|  5|In a tomato sauce...|<p>It seems that ...|[sauce, pasta, to...|\n",
      "|  6|What ingredients ...|<p>I have a recip...|[substitutions, h...|\n",
      "|  9|What is the inter...|<p>I'd like to kn...|[food-safety, bee...|\n",
      "| 11|How should I poac...|<p>What's the bes...|[eggs, basics, po...|\n",
      "| 12|How can I make my...|<p>My ice cream d...|         [ice-cream]|\n",
      "| 17|How long and at w...|<p>I'm interested...|[baking, chicken,...|\n",
      "| 23|Besides salmon, w...|<p>I've fallen in...|[grilling, salmon...|\n",
      "| 27|Do I need to sift...|<p>Is there reall...|[baking, flour, m...|\n",
      "| 28|Storage life for ...|<p>When I roast a...|[storage-method, ...|\n",
      "| 30|Pressure canning ...|<p>Where can safe...|[canning, pressur...|\n",
      "| 32|What's a good res...|<p>I know what sp...|[spices, resource...|\n",
      "| 36|Is it safe to lea...|<p>Is it safe to ...|[food-safety, sto...|\n",
      "| 38|Does resting the ...|<p>In this <a hre...|[baking, bread, d...|\n",
      "| 54|How should I prep...|<p>I've been watc...|[rice, italian-cu...|\n",
      "| 57|How does a splash...|<p>What does spla...|[eggs, food-scien...|\n",
      "| 61|What are the pros...|<p>Why should/sho...|[storage-method, ...|\n",
      "+---+--------------------+--------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_all.show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "87000"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_all.count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "val rdd = df_all.select(\"tags\").as[Seq[String]].rdd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(meet-in-the-middle-attack,5)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val tags = rdd.collect.flatMap(_.map(t => (t, t.split(\"-\").size)))\n",
    "val tagsDF = tags.toSeq.distinct.toDF(\"tag\", \"length\")\n",
    "\n",
    "tags.maxBy(_._2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+------+\n",
      "|                 tag|length|\n",
      "+--------------------+------+\n",
      "|              baking|     1|\n",
      "|             cookies|     1|\n",
      "|             texture|     1|\n",
      "|                oven|     1|\n",
      "|        cooking-time|     2|\n",
      "|               bacon|     1|\n",
      "|                eggs|     1|\n",
      "|       substitutions|     1|\n",
      "|please-remove-thi...|     4|\n",
      "|         baking-soda|     2|\n",
      "|       baking-powder|     2|\n",
      "|               sauce|     1|\n",
      "|               pasta|     1|\n",
      "|            tomatoes|     1|\n",
      "|     italian-cuisine|     2|\n",
      "|               herbs|     1|\n",
      "|             parsley|     1|\n",
      "|         food-safety|     2|\n",
      "|                beef|     1|\n",
      "|              basics|     1|\n",
      "+--------------------+------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tagsDF.show"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TODO: load all data and do a histogram over tag lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------------+------+\n",
      "|tag                      |length|\n",
      "+-------------------------+------+\n",
      "|meet-in-the-middle-attack|5     |\n",
      "|ho-chi-minh-city         |4     |\n",
      "|change-purpose-of-travel |4     |\n",
      "|san-francisco-bay-area   |4     |\n",
      "|please-remove-this-tag   |4     |\n",
      "|us-visa-waiver-program   |4     |\n",
      "|man-in-the-middle        |4     |\n",
      "|proof-provenance-of-funds|4     |\n",
      "|t-and-t-citizens         |4     |\n",
      "|90-180-visa-rules        |4     |\n",
      "|great-wall-of-china      |4     |\n",
      "|proof-of-onward-travel   |4     |\n",
      "|gondolas-and-cable-cars  |4     |\n",
      "|self-leveling-concrete   |3     |\n",
      "|glass-top-range          |3     |\n",
      "|diy-vs-pro               |3     |\n",
      "|damp-proof-course        |3     |\n",
      "|thermostat-c-wire        |3     |\n",
      "|grounding-and-bonding    |3     |\n",
      "|sliding-glass-door       |3     |\n",
      "+-------------------------+------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tagsDF.sort(-$\"length\").show(false)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import org.sameersingh.scalaplot.Implicits._\n",
    "val data = tags.map(_._2).groupBy(identity).mapValues(_.length)\n",
    "val (x, y) = data.toSeq.sortBy(_._1).map(x => (x._1.toDouble, x._2.toDouble)).unzip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<?xml version=\"1.0\" encoding=\"utf-8\"  standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<svg \n",
       " width=\"600\" height=\"480\"\n",
       " viewBox=\"0 0 600 480\"\n",
       " xmlns=\"http://www.w3.org/2000/svg\"\n",
       " xmlns:xlink=\"http://www.w3.org/1999/xlink\"\n",
       ">\n",
       "\n",
       "<title>Gnuplot</title>\n",
       "<desc>Produced by GNUPLOT 5.0 patchlevel 0 </desc>\n",
       "\n",
       "<g id=\"gnuplot_canvas\">\n",
       "\n",
       "<rect x=\"0\" y=\"0\" width=\"600\" height=\"480\" fill=\"none\"/>\n",
       "<defs>\n",
       "\n",
       "\t<circle id='gpDot' r='0.5' stroke-width='0.5'/>\n",
       "\t<path id='gpPt0' stroke-width='0.222' stroke='currentColor' d='M-1,0 h2 M0,-1 v2'/>\n",
       "\t<path id='gpPt1' stroke-width='0.222' stroke='currentColor' d='M-1,-1 L1,1 M1,-1 L-1,1'/>\n",
       "\t<path id='gpPt2' stroke-width='0.222' stroke='currentColor' d='M-1,0 L1,0 M0,-1 L0,1 M-1,-1 L1,1 M-1,1 L1,-1'/>\n",
       "\t<rect id='gpPt3' stroke-width='0.222' stroke='currentColor' x='-1' y='-1' width='2' height='2'/>\n",
       "\t<rect id='gpPt4' stroke-width='0.222' stroke='currentColor' fill='currentColor' x='-1' y='-1' width='2' height='2'/>\n",
       "\t<circle id='gpPt5' stroke-width='0.222' stroke='currentColor' cx='0' cy='0' r='1'/>\n",
       "\t<use xlink:href='#gpPt5' id='gpPt6' fill='currentColor' stroke='none'/>\n",
       "\t<path id='gpPt7' stroke-width='0.222' stroke='currentColor' d='M0,-1.33 L-1.33,0.67 L1.33,0.67 z'/>\n",
       "\t<use xlink:href='#gpPt7' id='gpPt8' fill='currentColor' stroke='none'/>\n",
       "\t<use xlink:href='#gpPt7' id='gpPt9' stroke='currentColor' transform='rotate(180)'/>\n",
       "\t<use xlink:href='#gpPt9' id='gpPt10' fill='currentColor' stroke='none'/>\n",
       "\t<use xlink:href='#gpPt3' id='gpPt11' stroke='currentColor' transform='rotate(45)'/>\n",
       "\t<use xlink:href='#gpPt11' id='gpPt12' fill='currentColor' stroke='none'/>\n",
       "\t<path id='gpPt13' stroke-width='0.222' stroke='currentColor' d='M0,1.330 L1.265,0.411 L0.782,-1.067 L-0.782,-1.076 L-1.265,0.411 z'/>\n",
       "\t<use xlink:href='#gpPt13' id='gpPt14' fill='currentColor' stroke='none'/>\n",
       "\t<filter id='textbox' filterUnits='objectBoundingBox' x='0' y='0' height='1' width='1'>\n",
       "\t  <feFlood flood-color='white' flood-opacity='1' result='bgnd'/>\n",
       "\t  <feComposite in='SourceGraphic' in2='bgnd' operator='atop'/>\n",
       "\t</filter>\n",
       "\t<filter id='greybox' filterUnits='objectBoundingBox' x='0' y='0' height='1' width='1'>\n",
       "\t  <feFlood flood-color='lightgrey' flood-opacity='1' result='grey'/>\n",
       "\t  <feComposite in='SourceGraphic' in2='grey' operator='atop'/>\n",
       "\t</filter>\n",
       "</defs>\n",
       "<g fill=\"none\" color=\"white\" stroke=\"currentColor\" stroke-width=\"3.00\" stroke-linecap=\"butt\" stroke-linejoin=\"miter\">\n",
       "</g>\n",
       "<g fill=\"none\" color=\"black\" stroke=\"currentColor\" stroke-width=\"3.00\" stroke-linecap=\"butt\" stroke-linejoin=\"miter\">\n",
       "\t<path stroke='black'  d='M78.8,444.0 L87.8,444.0 M575.0,444.0 L566.0,444.0  '/>\t<g transform=\"translate(70.5,448.5)\" stroke=\"none\" fill=\"black\" font-family=\"Arial\" font-size=\"12.00\"  text-anchor=\"end\">\n",
       "\t\t<text><tspan font-family=\"Arial\" > 0</tspan></text>\n",
       "\t</g>\n",
       "</g>\n",
       "<g fill=\"none\" color=\"black\" stroke=\"currentColor\" stroke-width=\"3.00\" stroke-linecap=\"butt\" stroke-linejoin=\"miter\">\n",
       "\t<path stroke='black'  d='M78.8,396.5 L87.8,396.5 M575.0,396.5 L566.0,396.5  '/>\t<g transform=\"translate(70.5,401.0)\" stroke=\"none\" fill=\"black\" font-family=\"Arial\" font-size=\"12.00\"  text-anchor=\"end\">\n",
       "\t\t<text><tspan font-family=\"Arial\" > 20000</tspan></text>\n",
       "\t</g>\n",
       "</g>\n",
       "<g fill=\"none\" color=\"black\" stroke=\"currentColor\" stroke-width=\"3.00\" stroke-linecap=\"butt\" stroke-linejoin=\"miter\">\n",
       "\t<path stroke='black'  d='M78.8,349.0 L87.8,349.0 M575.0,349.0 L566.0,349.0  '/>\t<g transform=\"translate(70.5,353.5)\" stroke=\"none\" fill=\"black\" font-family=\"Arial\" font-size=\"12.00\"  text-anchor=\"end\">\n",
       "\t\t<text><tspan font-family=\"Arial\" > 40000</tspan></text>\n",
       "\t</g>\n",
       "</g>\n",
       "<g fill=\"none\" color=\"black\" stroke=\"currentColor\" stroke-width=\"3.00\" stroke-linecap=\"butt\" stroke-linejoin=\"miter\">\n",
       "\t<path stroke='black'  d='M78.8,301.6 L87.8,301.6 M575.0,301.6 L566.0,301.6  '/>\t<g transform=\"translate(70.5,306.1)\" stroke=\"none\" fill=\"black\" font-family=\"Arial\" font-size=\"12.00\"  text-anchor=\"end\">\n",
       "\t\t<text><tspan font-family=\"Arial\" > 60000</tspan></text>\n",
       "\t</g>\n",
       "</g>\n",
       "<g fill=\"none\" color=\"black\" stroke=\"currentColor\" stroke-width=\"3.00\" stroke-linecap=\"butt\" stroke-linejoin=\"miter\">\n",
       "\t<path stroke='black'  d='M78.8,254.1 L87.8,254.1 M575.0,254.1 L566.0,254.1  '/>\t<g transform=\"translate(70.5,258.6)\" stroke=\"none\" fill=\"black\" font-family=\"Arial\" font-size=\"12.00\"  text-anchor=\"end\">\n",
       "\t\t<text><tspan font-family=\"Arial\" > 80000</tspan></text>\n",
       "\t</g>\n",
       "</g>\n",
       "<g fill=\"none\" color=\"black\" stroke=\"currentColor\" stroke-width=\"3.00\" stroke-linecap=\"butt\" stroke-linejoin=\"miter\">\n",
       "\t<path stroke='black'  d='M78.8,206.6 L87.8,206.6 M575.0,206.6 L566.0,206.6  '/>\t<g transform=\"translate(70.5,211.1)\" stroke=\"none\" fill=\"black\" font-family=\"Arial\" font-size=\"12.00\"  text-anchor=\"end\">\n",
       "\t\t<text><tspan font-family=\"Arial\" > 100000</tspan></text>\n",
       "\t</g>\n",
       "</g>\n",
       "<g fill=\"none\" color=\"black\" stroke=\"currentColor\" stroke-width=\"3.00\" stroke-linecap=\"butt\" stroke-linejoin=\"miter\">\n",
       "\t<path stroke='black'  d='M78.8,159.1 L87.8,159.1 M575.0,159.1 L566.0,159.1  '/>\t<g transform=\"translate(70.5,163.6)\" stroke=\"none\" fill=\"black\" font-family=\"Arial\" font-size=\"12.00\"  text-anchor=\"end\">\n",
       "\t\t<text><tspan font-family=\"Arial\" > 120000</tspan></text>\n",
       "\t</g>\n",
       "</g>\n",
       "<g fill=\"none\" color=\"black\" stroke=\"currentColor\" stroke-width=\"3.00\" stroke-linecap=\"butt\" stroke-linejoin=\"miter\">\n",
       "\t<path stroke='black'  d='M78.8,111.7 L87.8,111.7 M575.0,111.7 L566.0,111.7  '/>\t<g transform=\"translate(70.5,116.2)\" stroke=\"none\" fill=\"black\" font-family=\"Arial\" font-size=\"12.00\"  text-anchor=\"end\">\n",
       "\t\t<text><tspan font-family=\"Arial\" > 140000</tspan></text>\n",
       "\t</g>\n",
       "</g>\n",
       "<g fill=\"none\" color=\"black\" stroke=\"currentColor\" stroke-width=\"3.00\" stroke-linecap=\"butt\" stroke-linejoin=\"miter\">\n",
       "\t<path stroke='black'  d='M78.8,64.2 L87.8,64.2 M575.0,64.2 L566.0,64.2  '/>\t<g transform=\"translate(70.5,68.7)\" stroke=\"none\" fill=\"black\" font-family=\"Arial\" font-size=\"12.00\"  text-anchor=\"end\">\n",
       "\t\t<text><tspan font-family=\"Arial\" > 160000</tspan></text>\n",
       "\t</g>\n",
       "</g>\n",
       "<g fill=\"none\" color=\"black\" stroke=\"currentColor\" stroke-width=\"3.00\" stroke-linecap=\"butt\" stroke-linejoin=\"miter\">\n",
       "\t<path stroke='black'  d='M78.8,16.7 L87.8,16.7 M575.0,16.7 L566.0,16.7  '/>\t<g transform=\"translate(70.5,21.2)\" stroke=\"none\" fill=\"black\" font-family=\"Arial\" font-size=\"12.00\"  text-anchor=\"end\">\n",
       "\t\t<text><tspan font-family=\"Arial\" > 180000</tspan></text>\n",
       "\t</g>\n",
       "</g>\n",
       "<g fill=\"none\" color=\"black\" stroke=\"currentColor\" stroke-width=\"3.00\" stroke-linecap=\"butt\" stroke-linejoin=\"miter\">\n",
       "\t<path stroke='black'  d='M161.5,444.0 L161.5,435.0 M161.5,16.7 L161.5,25.7  '/>\t<g transform=\"translate(161.5,466.5)\" stroke=\"none\" fill=\"black\" font-family=\"Arial\" font-size=\"12.00\"  text-anchor=\"middle\">\n",
       "\t\t<text><tspan font-family=\"Arial\" >0</tspan></text>\n",
       "\t</g>\n",
       "</g>\n",
       "<g fill=\"none\" color=\"black\" stroke=\"currentColor\" stroke-width=\"3.00\" stroke-linecap=\"butt\" stroke-linejoin=\"miter\">\n",
       "\t<path stroke='black'  d='M244.2,444.0 L244.2,435.0 M244.2,16.7 L244.2,25.7  '/>\t<g transform=\"translate(244.2,466.5)\" stroke=\"none\" fill=\"black\" font-family=\"Arial\" font-size=\"12.00\"  text-anchor=\"middle\">\n",
       "\t\t<text><tspan font-family=\"Arial\" >1</tspan></text>\n",
       "\t</g>\n",
       "</g>\n",
       "<g fill=\"none\" color=\"black\" stroke=\"currentColor\" stroke-width=\"3.00\" stroke-linecap=\"butt\" stroke-linejoin=\"miter\">\n",
       "\t<path stroke='black'  d='M326.9,444.0 L326.9,435.0 M326.9,16.7 L326.9,25.7  '/>\t<g transform=\"translate(326.9,466.5)\" stroke=\"none\" fill=\"black\" font-family=\"Arial\" font-size=\"12.00\"  text-anchor=\"middle\">\n",
       "\t\t<text><tspan font-family=\"Arial\" >2</tspan></text>\n",
       "\t</g>\n",
       "</g>\n",
       "<g fill=\"none\" color=\"black\" stroke=\"currentColor\" stroke-width=\"3.00\" stroke-linecap=\"butt\" stroke-linejoin=\"miter\">\n",
       "\t<path stroke='black'  d='M409.6,444.0 L409.6,435.0 M409.6,16.7 L409.6,25.7  '/>\t<g transform=\"translate(409.6,466.5)\" stroke=\"none\" fill=\"black\" font-family=\"Arial\" font-size=\"12.00\"  text-anchor=\"middle\">\n",
       "\t\t<text><tspan font-family=\"Arial\" >3</tspan></text>\n",
       "\t</g>\n",
       "</g>\n",
       "<g fill=\"none\" color=\"black\" stroke=\"currentColor\" stroke-width=\"3.00\" stroke-linecap=\"butt\" stroke-linejoin=\"miter\">\n",
       "\t<path stroke='black'  d='M492.3,444.0 L492.3,435.0 M492.3,16.7 L492.3,25.7  '/>\t<g transform=\"translate(492.3,466.5)\" stroke=\"none\" fill=\"black\" font-family=\"Arial\" font-size=\"12.00\"  text-anchor=\"middle\">\n",
       "\t\t<text><tspan font-family=\"Arial\" >4</tspan></text>\n",
       "\t</g>\n",
       "</g>\n",
       "<g fill=\"none\" color=\"black\" stroke=\"currentColor\" stroke-width=\"3.00\" stroke-linecap=\"butt\" stroke-linejoin=\"miter\">\n",
       "</g>\n",
       "<g fill=\"none\" color=\"black\" stroke=\"currentColor\" stroke-width=\"3.00\" stroke-linecap=\"butt\" stroke-linejoin=\"miter\">\n",
       "\t<path stroke='black'  d='M78.8,16.7 L78.8,444.0 L575.0,444.0 L575.0,16.7 L78.8,16.7 Z  '/></g>\n",
       "<g fill=\"none\" color=\"black\" stroke=\"currentColor\" stroke-width=\"3.00\" stroke-linecap=\"butt\" stroke-linejoin=\"miter\">\n",
       "\t<g transform=\"translate(17.6,230.4) rotate(270)\" stroke=\"none\" fill=\"black\" font-family=\"Arial\" font-size=\"12.00\"  text-anchor=\"middle\">\n",
       "\t\t<text></text>\n",
       "\t</g>\n",
       "</g>\n",
       "<g fill=\"none\" color=\"black\" stroke=\"currentColor\" stroke-width=\"3.00\" stroke-linecap=\"butt\" stroke-linejoin=\"miter\">\n",
       "</g>\n",
       "<g fill=\"none\" color=\"black\" stroke=\"currentColor\" stroke-width=\"3.00\" stroke-linecap=\"butt\" stroke-linejoin=\"miter\">\n",
       "</g>\n",
       "\t<g id=\"gnuplot_plot_1\" ><title>Label</title>\n",
       "<g fill=\"none\" color=\"black\" stroke=\"currentColor\" stroke-width=\"3.00\" stroke-linecap=\"butt\" stroke-linejoin=\"miter\">\n",
       "\t<g stroke='none' shape-rendering='crispEdges'>\n",
       "\t\t<polygon fill = 'rgb(148,   0, 211)' points = '133.9,444.0 161.6,444.0 161.6,443.9 133.9,443.9 '/>\n",
       "\t</g>\n",
       "\t<path stroke='black'  d='M133.9,444.0 L161.5,444.0 L133.9,444.0 Z  '/></g>\n",
       "<g fill=\"none\" color=\"black\" stroke=\"currentColor\" stroke-width=\"3.00\" stroke-linecap=\"butt\" stroke-linejoin=\"miter\">\n",
       "\t<g stroke='none' shape-rendering='crispEdges'>\n",
       "\t\t<polygon fill = 'rgb(148,   0, 211)' points = '216.6,444.0 244.3,444.0 244.3,443.9 216.6,443.9 '/>\n",
       "\t</g>\n",
       "\t<path stroke='black'  d='M216.6,444.0 L244.2,444.0 L216.6,444.0 Z  '/></g>\n",
       "<g fill=\"none\" color=\"black\" stroke=\"currentColor\" stroke-width=\"3.00\" stroke-linecap=\"butt\" stroke-linejoin=\"miter\">\n",
       "\t<g stroke='none' shape-rendering='crispEdges'>\n",
       "\t\t<polygon fill = 'rgb(148,   0, 211)' points = '299.3,444.0 327.0,444.0 327.0,443.9 299.3,443.9 '/>\n",
       "\t</g>\n",
       "\t<path stroke='black'  d='M299.3,444.0 L326.9,444.0 L299.3,444.0 Z  '/></g>\n",
       "<g fill=\"none\" color=\"black\" stroke=\"currentColor\" stroke-width=\"3.00\" stroke-linecap=\"butt\" stroke-linejoin=\"miter\">\n",
       "\t<g stroke='none' shape-rendering='crispEdges'>\n",
       "\t\t<polygon fill = 'rgb(148,   0, 211)' points = '382.0,444.0 409.7,444.0 409.7,443.9 382.0,443.9 '/>\n",
       "\t</g>\n",
       "\t<path stroke='black'  d='M382.0,444.0 L409.6,444.0 L382.0,444.0 Z  '/></g>\n",
       "<g fill=\"none\" color=\"black\" stroke=\"currentColor\" stroke-width=\"3.00\" stroke-linecap=\"butt\" stroke-linejoin=\"miter\">\n",
       "\t<g stroke='none' shape-rendering='crispEdges'>\n",
       "\t\t<polygon fill = 'rgb(148,   0, 211)' points = '464.7,444.0 492.4,444.0 492.4,443.9 464.7,443.9 '/>\n",
       "\t</g>\n",
       "\t<path stroke='black'  d='M464.7,444.0 L492.3,444.0 L464.7,444.0 Z  '/></g>\n",
       "<g fill=\"none\" color=\"black\" stroke=\"currentColor\" stroke-width=\"3.00\" stroke-linecap=\"butt\" stroke-linejoin=\"miter\">\n",
       "</g>\n",
       "\t</g>\n",
       "\t<g id=\"gnuplot_plot_2\" ><title>Label</title>\n",
       "<g fill=\"none\" color=\"black\" stroke=\"currentColor\" stroke-width=\"3.00\" stroke-linecap=\"butt\" stroke-linejoin=\"miter\">\n",
       "\t<g stroke='none' shape-rendering='crispEdges'>\n",
       "\t\t<polygon fill = 'rgb(  0, 158, 115)' points = '161.5,444.0 189.2,444.0 189.2,53.7 161.5,53.7 '/>\n",
       "\t</g>\n",
       "\t<path stroke='black'  d='M161.5,444.0 L161.5,53.8 L189.1,53.8 L189.1,444.0 L161.5,444.0 Z  '/></g>\n",
       "<g fill=\"none\" color=\"black\" stroke=\"currentColor\" stroke-width=\"3.00\" stroke-linecap=\"butt\" stroke-linejoin=\"miter\">\n",
       "\t<g stroke='none' shape-rendering='crispEdges'>\n",
       "\t\t<polygon fill = 'rgb(  0, 158, 115)' points = '244.2,444.0 271.9,444.0 271.9,318.1 244.2,318.1 '/>\n",
       "\t</g>\n",
       "\t<path stroke='black'  d='M244.2,444.0 L244.2,318.2 L271.8,318.2 L271.8,444.0 L244.2,444.0 Z  '/></g>\n",
       "<g fill=\"none\" color=\"black\" stroke=\"currentColor\" stroke-width=\"3.00\" stroke-linecap=\"butt\" stroke-linejoin=\"miter\">\n",
       "\t<g stroke='none' shape-rendering='crispEdges'>\n",
       "\t\t<polygon fill = 'rgb(  0, 158, 115)' points = '326.9,444.0 354.6,444.0 354.6,426.5 326.9,426.5 '/>\n",
       "\t</g>\n",
       "\t<path stroke='black'  d='M326.9,444.0 L326.9,426.6 L354.5,426.6 L354.5,444.0 L326.9,444.0 Z  '/></g>\n",
       "<g fill=\"none\" color=\"black\" stroke=\"currentColor\" stroke-width=\"3.00\" stroke-linecap=\"butt\" stroke-linejoin=\"miter\">\n",
       "\t<g stroke='none' shape-rendering='crispEdges'>\n",
       "\t\t<polygon fill = 'rgb(  0, 158, 115)' points = '409.6,444.0 437.3,444.0 437.3,442.7 409.6,442.7 '/>\n",
       "\t</g>\n",
       "\t<path stroke='black'  d='M409.6,444.0 L409.6,442.8 L437.2,442.8 L437.2,444.0 L409.6,444.0 Z  '/></g>\n",
       "<g fill=\"none\" color=\"black\" stroke=\"currentColor\" stroke-width=\"3.00\" stroke-linecap=\"butt\" stroke-linejoin=\"miter\">\n",
       "\t<g stroke='none' shape-rendering='crispEdges'>\n",
       "\t\t<polygon fill = 'rgb(  0, 158, 115)' points = '492.3,444.0 520.0,444.0 520.0,443.8 492.3,443.8 '/>\n",
       "\t</g>\n",
       "\t<path stroke='black'  d='M492.3,444.0 L492.3,443.9 L519.9,443.9 L519.9,444.0 L492.3,444.0 Z  '/></g>\n",
       "<g fill=\"none\" color=\"black\" stroke=\"currentColor\" stroke-width=\"3.00\" stroke-linecap=\"butt\" stroke-linejoin=\"miter\">\n",
       "</g>\n",
       "\t</g>\n",
       "<g fill=\"none\" color=\"white\" stroke=\"rgb(  0, 158, 115)\" stroke-width=\"6.00\" stroke-linecap=\"butt\" stroke-linejoin=\"miter\">\n",
       "</g>\n",
       "<g fill=\"none\" color=\"black\" stroke=\"currentColor\" stroke-width=\"6.00\" stroke-linecap=\"butt\" stroke-linejoin=\"miter\">\n",
       "</g>\n",
       "<g fill=\"none\" color=\"black\" stroke=\"black\" stroke-width=\"3.00\" stroke-linecap=\"butt\" stroke-linejoin=\"miter\">\n",
       "</g>\n",
       "<g fill=\"none\" color=\"black\" stroke=\"currentColor\" stroke-width=\"3.00\" stroke-linecap=\"butt\" stroke-linejoin=\"miter\">\n",
       "\t<path stroke='black'  d='M78.8,16.7 L78.8,444.0 L575.0,444.0 L575.0,16.7 L78.8,16.7 Z  '/></g>\n",
       "<g fill=\"none\" color=\"black\" stroke=\"currentColor\" stroke-width=\"3.00\" stroke-linecap=\"butt\" stroke-linejoin=\"miter\">\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n",
       "\n"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kernel.magics.html(output(SVG, barChart(x -> y)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Name: org.apache.spark.SparkException\n",
       "Message: Task not serializable\n",
       "StackTrace:   at org.apache.spark.util.ClosureCleaner$.ensureSerializable(ClosureCleaner.scala:298)\n",
       "  at org.apache.spark.util.ClosureCleaner$.org$apache$spark$util$ClosureCleaner$$clean(ClosureCleaner.scala:288)\n",
       "  at org.apache.spark.util.ClosureCleaner$.clean(ClosureCleaner.scala:108)\n",
       "  at org.apache.spark.SparkContext.clean(SparkContext.scala:2056)\n",
       "  at org.apache.spark.rdd.RDD$$anonfun$mapPartitionsWithIndex$1.apply(RDD.scala:817)\n",
       "  at org.apache.spark.rdd.RDD$$anonfun$mapPartitionsWithIndex$1.apply(RDD.scala:816)\n",
       "  at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n",
       "  at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\n",
       "  at org.apache.spark.rdd.RDD.withScope(RDD.scala:358)\n",
       "  at org.apache.spark.rdd.RDD.mapPartitionsWithIndex(RDD.scala:816)\n",
       "  at org.apache.spark.sql.execution.WholeStageCodegenExec.doExecute(WholeStageCodegenExec.scala:364)\n",
       "  at org.apache.spark.sql.execution.SparkPlan$$anonfun$execute$1.apply(SparkPlan.scala:115)\n",
       "  at org.apache.spark.sql.execution.SparkPlan$$anonfun$execute$1.apply(SparkPlan.scala:115)\n",
       "  at org.apache.spark.sql.execution.SparkPlan$$anonfun$executeQuery$1.apply(SparkPlan.scala:136)\n",
       "  at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n",
       "  at org.apache.spark.sql.execution.SparkPlan.executeQuery(SparkPlan.scala:133)\n",
       "  at org.apache.spark.sql.execution.SparkPlan.execute(SparkPlan.scala:114)\n",
       "  at org.apache.spark.sql.execution.exchange.ShuffleExchange.prepareShuffleDependency(ShuffleExchange.scala:87)\n",
       "  at org.apache.spark.sql.execution.exchange.ShuffleExchange$$anonfun$doExecute$1.apply(ShuffleExchange.scala:123)\n",
       "  at org.apache.spark.sql.execution.exchange.ShuffleExchange$$anonfun$doExecute$1.apply(ShuffleExchange.scala:114)\n",
       "  at org.apache.spark.sql.catalyst.errors.package$.attachTree(package.scala:52)\n",
       "  at org.apache.spark.sql.execution.exchange.ShuffleExchange.doExecute(ShuffleExchange.scala:114)\n",
       "  at org.apache.spark.sql.execution.SparkPlan$$anonfun$execute$1.apply(SparkPlan.scala:115)\n",
       "  at org.apache.spark.sql.execution.SparkPlan$$anonfun$execute$1.apply(SparkPlan.scala:115)\n",
       "  at org.apache.spark.sql.execution.SparkPlan$$anonfun$executeQuery$1.apply(SparkPlan.scala:136)\n",
       "  at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n",
       "  at org.apache.spark.sql.execution.SparkPlan.executeQuery(SparkPlan.scala:133)\n",
       "  at org.apache.spark.sql.execution.SparkPlan.execute(SparkPlan.scala:114)\n",
       "  at org.apache.spark.sql.execution.InputAdapter.inputRDDs(WholeStageCodegenExec.scala:233)\n",
       "  at org.apache.spark.sql.execution.aggregate.HashAggregateExec.inputRDDs(HashAggregateExec.scala:138)\n",
       "  at org.apache.spark.sql.execution.WholeStageCodegenExec.doExecute(WholeStageCodegenExec.scala:361)\n",
       "  at org.apache.spark.sql.execution.SparkPlan$$anonfun$execute$1.apply(SparkPlan.scala:115)\n",
       "  at org.apache.spark.sql.execution.SparkPlan$$anonfun$execute$1.apply(SparkPlan.scala:115)\n",
       "  at org.apache.spark.sql.execution.SparkPlan$$anonfun$executeQuery$1.apply(SparkPlan.scala:136)\n",
       "  at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n",
       "  at org.apache.spark.sql.execution.SparkPlan.executeQuery(SparkPlan.scala:133)\n",
       "  at org.apache.spark.sql.execution.SparkPlan.execute(SparkPlan.scala:114)\n",
       "  at org.apache.spark.sql.execution.SparkPlan.getByteArrayRdd(SparkPlan.scala:240)\n",
       "  at org.apache.spark.sql.execution.SparkPlan.executeCollect(SparkPlan.scala:287)\n",
       "  at org.apache.spark.sql.Dataset$$anonfun$org$apache$spark$sql$Dataset$$execute$1$1.apply(Dataset.scala:2193)\n",
       "  at org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:57)\n",
       "  at org.apache.spark.sql.Dataset.withNewExecutionId(Dataset.scala:2546)\n",
       "  at org.apache.spark.sql.Dataset.org$apache$spark$sql$Dataset$$execute$1(Dataset.scala:2192)\n",
       "  at org.apache.spark.sql.Dataset$$anonfun$org$apache$spark$sql$Dataset$$collect$1.apply(Dataset.scala:2197)\n",
       "  at org.apache.spark.sql.Dataset$$anonfun$org$apache$spark$sql$Dataset$$collect$1.apply(Dataset.scala:2197)\n",
       "  at org.apache.spark.sql.Dataset.withCallback(Dataset.scala:2559)\n",
       "  at org.apache.spark.sql.Dataset.org$apache$spark$sql$Dataset$$collect(Dataset.scala:2197)\n",
       "  at org.apache.spark.sql.Dataset.collect(Dataset.scala:2173)\n",
       "  ... 48 elided\n",
       "Caused by: java.io.NotSerializableException: scala.collection.immutable.MapLike$$anon$2\n",
       "Serialization stack:\n",
       "\t- object not serializable (class: scala.collection.immutable.MapLike$$anon$2, value: Map(5 -> 29, 1 -> 164356, 2 -> 52990, 3 -> 7346, 4 -> 511))\n",
       "\t- field (class: $iw, name: data, type: interface scala.collection.immutable.Map)\n",
       "\t- object (class $iw, $iw@5e2ce42c)\n",
       "\t- field (class: $iw, name: $iw, type: class $iw)\n",
       "\t- object (class $iw, $iw@769ef83f)\n",
       "\t- field (class: $iw, name: $iw, type: class $iw)\n",
       "\t- object (class $iw, $iw@64938cd3)\n",
       "\t- field (class: $iw, name: $iw, type: class $iw)\n",
       "\t- object (class $iw, $iw@322c57ff)\n",
       "\t- field (class: $iw, name: $iw, type: class $iw)\n",
       "\t- object (class $iw, $iw@40a3b49d)\n",
       "\t- field (class: $iw, name: $iw, type: class $iw)\n",
       "\t- object (class $iw, $iw@1fda6891)\n",
       "\t- field (class: $iw, name: $iw, type: class $iw)\n",
       "\t- object (class $iw, $iw@2bde1cb1)\n",
       "\t- field (class: $iw, name: $iw, type: class $iw)\n",
       "\t- object (class $iw, $iw@12809cd6)\n",
       "\t- field (class: $iw, name: $iw, type: class $iw)\n",
       "\t- object (class $iw, $iw@4cb8d069)\n",
       "\t- field (class: $iw, name: $iw, type: class $iw)\n",
       "\t- object (class $iw, $iw@63669a74)\n",
       "\t- field (class: $iw, name: $iw, type: class $iw)\n",
       "\t- object (class $iw, $iw@503c8a6a)\n",
       "\t- field (class: $iw, name: $iw, type: class $iw)\n",
       "\t- object (class $iw, $iw@206ba9a0)\n",
       "\t- field (class: $line48.$read, name: $iw, type: class $iw)\n",
       "\t- object (class $line48.$read, $line48.$read@5e5b33bc)\n",
       "\t- field (class: $iw, name: $line48$read, type: class $line48.$read)\n",
       "\t- object (class $iw, $iw@48cceb28)\n",
       "\t- field (class: $iw, name: $iw, type: class $iw)\n",
       "\t- object (class $iw, $iw@1b8e7f38)\n",
       "\t- field (class: $iw, name: $iw, type: class $iw)\n",
       "\t- object (class $iw, $iw@5c1c63d4)\n",
       "\t- field (class: $iw, name: $iw, type: class $iw)\n",
       "\t- object (class $iw, $iw@37d5c7f4)\n",
       "\t- field (class: $iw, name: $iw, type: class $iw)\n",
       "\t- object (class $iw, $iw@77f57d4c)\n",
       "\t- field (class: $iw, name: $iw, type: class $iw)\n",
       "\t- object (class $iw, $iw@49a2efe4)\n",
       "\t- field (class: $iw, name: $iw, type: class $iw)\n",
       "\t- object (class $iw, $iw@442b68df)\n",
       "\t- field (class: $iw, name: $iw, type: class $iw)\n",
       "\t- object (class $iw, $iw@5f1f9f2)\n",
       "\t- field (class: $iw, name: $iw, type: class $iw)\n",
       "\t- object (class $iw, $iw@3e0f9ce8)\n",
       "\t- field (class: $iw, name: $iw, type: class $iw)\n",
       "\t- object (class $iw, $iw@2b74e019)\n",
       "\t- field (class: $iw, name: $iw, type: class $iw)\n",
       "\t- object (class $iw, $iw@3ceb1af2)\n",
       "\t- field (class: $line49.$read, name: $iw, type: class $iw)\n",
       "\t- object (class $line49.$read, $line49.$read@5dc2dad5)\n",
       "\t- field (class: $iw, name: $line49$read, type: class $line49.$read)\n",
       "\t- object (class $iw, $iw@4f9cfc31)\n",
       "\t- field (class: $iw, name: $outer, type: class $iw)\n",
       "\t- object (class $iw, $iw@3ba30db3)\n",
       "\t- field (class: $anonfun$1, name: $outer, type: class $iw)\n",
       "\t- object (class $anonfun$1, <function1>)\n",
       "\t- field (class: org.apache.spark.sql.Dataset$$anonfun$flatMap$1, name: func$5, type: interface scala.Function1)\n",
       "\t- object (class org.apache.spark.sql.Dataset$$anonfun$flatMap$1, <function1>)\n",
       "\t- field (class: org.apache.spark.sql.execution.MapPartitionsExec, name: func, type: interface scala.Function1)\n",
       "\t- object (class org.apache.spark.sql.execution.MapPartitionsExec, MapPartitions <function1>, obj#191: java.lang.String\n",
       "+- DeserializeToObject content#62.toString, obj#190: java.lang.String\n",
       "   +- Union\n",
       "      :- *Scan csv [content#62] Format: CSV, InputPaths: file:/home/evan/dev/KaggleCompetitions/StackExchange/dat/cooking_clean.csv, PartitionFilters: [], PushedFilters: [], ReadSchema: struct<content:string>\n",
       "      :- *Scan csv [content#71] Format: CSV, InputPaths: file:/home/evan/dev/KaggleCompetitions/StackExchange/dat/crypto_clean.csv, PartitionFilters: [], PushedFilters: [], ReadSchema: struct<content:string>\n",
       "      :- *Scan csv [content#80] Format: CSV, InputPaths: file:/home/evan/dev/KaggleCompetitions/StackExchange/dat/robotics_clean.csv, PartitionFilters: [], PushedFilters: [], ReadSchema: struct<content:string>\n",
       "      :- *Scan csv [content#89] Format: CSV, InputPaths: file:/home/evan/dev/KaggleCompetitions/StackExchange/dat/biology_clean.csv, PartitionFilters: [], PushedFilters: [], ReadSchema: struct<content:string>\n",
       "      :- *Scan csv [content#98] Format: CSV, InputPaths: file:/home/evan/dev/KaggleCompetitions/StackExchange/dat/travel_clean.csv, PartitionFilters: [], PushedFilters: [], ReadSchema: struct<content:string>\n",
       "      +- *Scan csv [content#107] Format: CSV, InputPaths: file:/home/evan/dev/KaggleCompetitions/StackExchange/dat/diy_clean.csv, PartitionFilters: [], PushedFilters: [], ReadSchema: struct<content:string>\n",
       ")\n",
       "\t- field (class: org.apache.spark.sql.execution.InputAdapter, name: child, type: class org.apache.spark.sql.execution.SparkPlan)\n",
       "\t- object (class org.apache.spark.sql.execution.InputAdapter, MapPartitions <function1>, obj#191: java.lang.String\n",
       "+- DeserializeToObject content#62.toString, obj#190: java.lang.String\n",
       "   +- Union\n",
       "      :- *Scan csv [content#62] Format: CSV, InputPaths: file:/home/evan/dev/KaggleCompetitions/StackExchange/dat/cooking_clean.csv, PartitionFilters: [], PushedFilters: [], ReadSchema: struct<content:string>\n",
       "      :- *Scan csv [content#71] Format: CSV, InputPaths: file:/home/evan/dev/KaggleCompetitions/StackExchange/dat/crypto_clean.csv, PartitionFilters: [], PushedFilters: [], ReadSchema: struct<content:string>\n",
       "      :- *Scan csv [content#80] Format: CSV, InputPaths: file:/home/evan/dev/KaggleCompetitions/StackExchange/dat/robotics_clean.csv, PartitionFilters: [], PushedFilters: [], ReadSchema: struct<content:string>\n",
       "      :- *Scan csv [content#89] Format: CSV, InputPaths: file:/home/evan/dev/KaggleCompetitions/StackExchange/dat/biology_clean.csv, PartitionFilters: [], PushedFilters: [], ReadSchema: struct<content:string>\n",
       "      :- *Scan csv [content#98] Format: CSV, InputPaths: file:/home/evan/dev/KaggleCompetitions/StackExchange/dat/travel_clean.csv, PartitionFilters: [], PushedFilters: [], ReadSchema: struct<content:string>\n",
       "      +- *Scan csv [content#107] Format: CSV, InputPaths: file:/home/evan/dev/KaggleCompetitions/StackExchange/dat/diy_clean.csv, PartitionFilters: [], PushedFilters: [], ReadSchema: struct<content:string>\n",
       ")\n",
       "\t- field (class: org.apache.spark.sql.execution.SerializeFromObjectExec, name: child, type: class org.apache.spark.sql.execution.SparkPlan)\n",
       "\t- object (class org.apache.spark.sql.execution.SerializeFromObjectExec, SerializeFromObject [staticinvoke(class org.apache.spark.unsafe.types.UTF8String, StringType, fromString, input[0, java.lang.String, true], true) AS value#192]\n",
       "+- MapPartitions <function1>, obj#191: java.lang.String\n",
       "   +- DeserializeToObject content#62.toString, obj#190: java.lang.String\n",
       "      +- Union\n",
       "         :- *Scan csv [content#62] Format: CSV, InputPaths: file:/home/evan/dev/KaggleCompetitions/StackExchange/dat/cooking_clean.csv, PartitionFilters: [], PushedFilters: [], ReadSchema: struct<content:string>\n",
       "         :- *Scan csv [content#71] Format: CSV, InputPaths: file:/home/evan/dev/KaggleCompetitions/StackExchange/dat/crypto_clean.csv, PartitionFilters: [], PushedFilters: [], ReadSchema: struct<content:string>\n",
       "         :- *Scan csv [content#80] Format: CSV, InputPaths: file:/home/evan/dev/KaggleCompetitions/StackExchange/dat/robotics_clean.csv, PartitionFilters: [], PushedFilters: [], ReadSchema: struct<content:string>\n",
       "         :- *Scan csv [content#89] Format: CSV, InputPaths: file:/home/evan/dev/KaggleCompetitions/StackExchange/dat/biology_clean.csv, PartitionFilters: [], PushedFilters: [], ReadSchema: struct<content:string>\n",
       "         :- *Scan csv [content#98] Format: CSV, InputPaths: file:/home/evan/dev/KaggleCompetitions/StackExchange/dat/travel_clean.csv, PartitionFilters: [], PushedFilters: [], ReadSchema: struct<content:string>\n",
       "         +- *Scan csv [content#107] Format: CSV, InputPaths: file:/home/evan/dev/KaggleCompetitions/StackExchange/dat/diy_clean.csv, PartitionFilters: [], PushedFilters: [], ReadSchema: struct<content:string>\n",
       ")\n",
       "\t- field (class: org.apache.spark.sql.execution.aggregate.HashAggregateExec, name: child, type: class org.apache.spark.sql.execution.SparkPlan)\n",
       "\t- object (class org.apache.spark.sql.execution.aggregate.HashAggregateExec, HashAggregate(keys=[value#192], functions=[], output=[value#192])\n",
       "+- SerializeFromObject [staticinvoke(class org.apache.spark.unsafe.types.UTF8String, StringType, fromString, input[0, java.lang.String, true], true) AS value#192]\n",
       "   +- MapPartitions <function1>, obj#191: java.lang.String\n",
       "      +- DeserializeToObject content#62.toString, obj#190: java.lang.String\n",
       "         +- Union\n",
       "            :- *Scan csv [content#62] Format: CSV, InputPaths: file:/home/evan/dev/KaggleCompetitions/StackExchange/dat/cooking_clean.csv, PartitionFilters: [], PushedFilters: [], ReadSchema: struct<content:string>\n",
       "            :- *Scan csv [content#71] Format: CSV, InputPaths: file:/home/evan/dev/KaggleCompetitions/StackExchange/dat/crypto_clean.csv, PartitionFilters: [], PushedFilters: [], ReadSchema: struct<content:string>\n",
       "            :- *Scan csv [content#80] Format: CSV, InputPaths: file:/home/evan/dev/KaggleCompetitions/StackExchange/dat/robotics_clean.csv, PartitionFilters: [], PushedFilters: [], ReadSchema: struct<content:string>\n",
       "            :- *Scan csv [content#89] Format: CSV, InputPaths: file:/home/evan/dev/KaggleCompetitions/StackExchange/dat/biology_clean.csv, PartitionFilters: [], PushedFilters: [], ReadSchema: struct<content:string>\n",
       "            :- *Scan csv [content#98] Format: CSV, InputPaths: file:/home/evan/dev/KaggleCompetitions/StackExchange/dat/travel_clean.csv, PartitionFilters: [], PushedFilters: [], ReadSchema: struct<content:string>\n",
       "            +- *Scan csv [content#107] Format: CSV, InputPaths: file:/home/evan/dev/KaggleCompetitions/StackExchange/dat/diy_clean.csv, PartitionFilters: [], PushedFilters: [], ReadSchema: struct<content:string>\n",
       ")\n",
       "\t- element of array (index: 0)\n",
       "\t- array (class [Ljava.lang.Object;, size 5)\n",
       "\t- field (class: org.apache.spark.sql.execution.WholeStageCodegenExec$$anonfun$8, name: references$1, type: class [Ljava.lang.Object;)\n",
       "\t- object (class org.apache.spark.sql.execution.WholeStageCodegenExec$$anonfun$8, <function2>)\n",
       "  at org.apache.spark.serializer.SerializationDebugger$.improveException(SerializationDebugger.scala:40)\n",
       "  at org.apache.spark.serializer.JavaSerializationStream.writeObject(JavaSerializer.scala:46)\n",
       "  at org.apache.spark.serializer.JavaSerializerInstance.serialize(JavaSerializer.scala:100)\n",
       "  at org.apache.spark.util.ClosureCleaner$.ensureSerializable(ClosureCleaner.scala:295)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val tagMatcher = \"\"\"<((?!>).{1,5})>\"\"\".r\n",
    "val htmlTags = df_all.select(\"content\").as[String].flatMap(x => tagMatcher.findAllIn(x).toList).distinct.collect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Name: Unknown Error\n",
       "Message: lastException: Throwable = null\n",
       "<console>:32: error: not found: value htmlTags\n",
       "       println(s\"Number of tags: ${htmlTags.length}\")\n",
       "                                   ^\n",
       "StackTrace: "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "println(s\"Number of tags: ${htmlTags.length}\")\n",
    "htmlTags.foreach{println}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Apache Toree - Scala",
   "language": "scala",
   "name": "apache_toree_scala"
  },
  "language_info": {
   "file_extension": ".scala",
   "name": "scala",
   "version": "2.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
