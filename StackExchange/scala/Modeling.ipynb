{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Marking edu.stanford.nlp:stanford-corenlp:3.7.0 for download\n",
      "Preparing to fetch from:\n",
      "-> file:/tmp/toree_add_deps6278997845129245926/\n",
      "-> https://repo1.maven.org/maven2\n",
      "-> New file at /tmp/toree_add_deps6278997845129245926/https/repo1.maven.org/maven2/edu/stanford/nlp/stanford-corenlp/3.7.0/stanford-corenlp-3.7.0.jar\n",
      "Marking com.google.protobuf:protobuf-java:2.6.1 for download\n",
      "Preparing to fetch from:\n",
      "-> file:/tmp/toree_add_deps6278997845129245926/\n",
      "-> https://repo1.maven.org/maven2\n",
      "-> New file at /tmp/toree_add_deps6278997845129245926/https/repo1.maven.org/maven2/com/google/protobuf/protobuf-java/2.6.1/protobuf-java-2.6.1.jar\n",
      "Marking com.databricks:spark-csv_2.10:1.5.0 for download\n",
      "Preparing to fetch from:\n",
      "-> file:/tmp/toree_add_deps6278997845129245926/\n",
      "-> https://repo1.maven.org/maven2\n",
      "-> New file at /tmp/toree_add_deps6278997845129245926/https/repo1.maven.org/maven2/com/databricks/spark-csv_2.10/1.5.0/spark-csv_2.10-1.5.0.jar\n",
      "-> New file at /tmp/toree_add_deps6278997845129245926/https/repo1.maven.org/maven2/org/apache/commons/commons-csv/1.1/commons-csv-1.1.jar\n",
      "-> New file at /tmp/toree_add_deps6278997845129245926/https/repo1.maven.org/maven2/com/univocity/univocity-parsers/1.5.1/univocity-parsers-1.5.1.jar\n",
      "Starting download from file:lib/corenlp-models.jar\n",
      "Finished download of corenlp-models.jar\n",
      "Starting download from file:SE/target/scala-2.10/se_2.10-1.1.jar\n",
      "Finished download of se_2.10-1.1.jar\n"
     ]
    }
   ],
   "source": [
    "/* Add Deps */\n",
    "%AddDeps edu.stanford.nlp stanford-corenlp 3.7.0\n",
    "%AddDeps com.google.protobuf protobuf-java 2.6.1\n",
    "%AddDeps com.databricks spark-csv_2.10 1.5.0 --transitive\n",
    "\n",
    "// Non-repo dependencies \n",
    "%AddJar file:lib/corenlp-models.jar\n",
    "%AddJar file:SE/target/scala-2.10/se_2.10-1.1.jar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import com.evan.kaggle.se.FeatureEngineering._\n",
    "val sqlContext = org.apache.spark.sql.SQLContext.getOrCreate(sc)\n",
    "import sqlContext.implicits._\n",
    "import org.apache.spark.sql.functions._\n",
    "import org.apache.spark.sql.Row\n",
    "import scala.collection.immutable.HashSet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Name: Syntax Error.\n",
       "Message: \n",
       "StackTrace: "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// val files = List(\"cooking\")//, \"crypto\", \"robotics\", \"biology\", \"travel\", \"diy\")\n",
    "\n",
    "// /* Load and print all files */\n",
    "// val df_all = files.map(f => {\n",
    "//                         sqlContext.read.format(\"com.databricks.spark.csv\").option(\"header\", \"true\").load(\"../dat/\"+f+\"_clean.csv\")\n",
    "//                    }).reduce(_ unionAll _).filter($\"content\" !== \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "val samp = sqlContext.read.parquet(\"union.parquet\").sample(false, .5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "43496"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "samp.count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "val feat_udf = udf((t: String, c: String, ta: String) => \n",
    "    makeTrFeatures(3)(t, c, ta))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "val flat = samp.select(explode(feat_udf($\"title\", $\"content\", $\"tags\")))\n",
    "val flat2 = flat.select($\"col.*\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import org.apache.spark.ml.Pipeline\n",
    "import org.apache.spark.ml.classification.{RandomForestClassificationModel, RandomForestClassifier}\n",
    "import org.apache.spark.ml.evaluation.MulticlassClassificationEvaluator\n",
    "import org.apache.spark.ml.feature.{IndexToString, StringIndexer, VectorIndexer}\n",
    "import org.apache.spark.ml.feature.{HashingTF, IDF, Tokenizer}\n",
    "import org.apache.spark.ml.feature.VectorAssembler\n",
    "\n",
    "//change name\n",
    "val data = flat2.withColumn(\"isTag\", when($\"isTag\", lit(\"Y\")).otherwise(lit(\"N\"))).\n",
    "    withColumn(\"hasUpper\", when($\"hasUpper\", lit(1.0)).otherwise(0.0))\n",
    "\n",
    "val labelIndexer = new StringIndexer().\n",
    "  setInputCol(\"isTag\").\n",
    "  setOutputCol(\"indexedLabel\").\n",
    "  fit(data)\n",
    "\n",
    "val hashingTF = new HashingTF().setInputCol(\"posTags\").\n",
    "    setInputCol(\"depTags\").\n",
    "    setOutputCol(\"rawFeatures\").setNumFeatures(20)\n",
    "\n",
    "val idf = new IDF().setInputCol(\"rawFeatures\").\n",
    "    setOutputCol(\"text_features\")\n",
    "\n",
    "val assembler = new VectorAssembler().\n",
    "    setInputCols(Array(\"text_features\", \"relPos\", \"hasUpper\", \"numWords\")).\n",
    "    setOutputCol(\"features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "// Split the data into training and test sets (30% held out for testing)\n",
    "val Array(trainingData, testData) = data.randomSplit(Array(0.7, 0.3))\n",
    "\n",
    "// Train a RandomForest model.\n",
    "val rf = new RandomForestClassifier().setLabelCol(\"indexedLabel\").\n",
    "  setFeaturesCol(\"features\").\n",
    "  setNumTrees(10)\n",
    "\n",
    "// Convert indexed labels back to original labels.\n",
    "val labelConverter = new IndexToString().\n",
    "  setInputCol(\"prediction\").\n",
    "  setOutputCol(\"predictedLabel\").\n",
    "  setLabels(labelIndexer.labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "// Chain indexers and forest in a Pipeline\n",
    "val pipeline = new Pipeline().setStages(Array(labelIndexer, hashingTF, idf, assembler, rf, labelConverter))\n",
    "\n",
    "// Train model.  This also runs the indexers.\n",
    "val model = pipeline.fit(trainingData)\n",
    "\n",
    "// Make predictions.\n",
    "val predictions = model.transform(testData)\n",
    "\n",
    "// Select example rows to display.\n",
    "predictions.select(\"predictedLabel\", \"indexedLabel\", \"features\").show(5)\n",
    "\n",
    "// Select (prediction, true label) and compute test error\n",
    "val evaluator = new MulticlassClassificationEvaluator().setLabelCol(\"indexedLabel\").\n",
    "  setPredictionCol(\"prediction\").\n",
    "  setMetricName(\"precision\")\n",
    "val accuracy = evaluator.evaluate(predictions)\n",
    "println(\"Test Error = \" + (1.0 - accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data.write.save(\"featurized.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Apache Toree - Scala",
   "language": "scala",
   "name": "apache_toree_scala"
  },
  "language_info": {
   "name": "scala",
   "version": "2.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
