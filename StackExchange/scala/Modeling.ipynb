{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Marking edu.stanford.nlp:stanford-corenlp:3.7.0 for download\n",
      "Preparing to fetch from:\n",
      "-> file:/tmp/toree_add_deps1635466249893929454/\n",
      "-> https://repo1.maven.org/maven2\n",
      "-> New file at /tmp/toree_add_deps1635466249893929454/https/repo1.maven.org/maven2/edu/stanford/nlp/stanford-corenlp/3.7.0/stanford-corenlp-3.7.0.jar\n",
      "Marking com.google.protobuf:protobuf-java:2.6.1 for download\n",
      "Preparing to fetch from:\n",
      "-> file:/tmp/toree_add_deps1635466249893929454/\n",
      "-> https://repo1.maven.org/maven2\n",
      "-> New file at /tmp/toree_add_deps1635466249893929454/https/repo1.maven.org/maven2/com/google/protobuf/protobuf-java/2.6.1/protobuf-java-2.6.1.jar\n",
      "Marking com.databricks:spark-csv_2.10:1.5.0 for download\n",
      "Preparing to fetch from:\n",
      "-> file:/tmp/toree_add_deps1635466249893929454/\n",
      "-> https://repo1.maven.org/maven2\n",
      "-> New file at /tmp/toree_add_deps1635466249893929454/https/repo1.maven.org/maven2/org/apache/commons/commons-csv/1.1/commons-csv-1.1.jar\n",
      "-> New file at /tmp/toree_add_deps1635466249893929454/https/repo1.maven.org/maven2/com/databricks/spark-csv_2.10/1.5.0/spark-csv_2.10-1.5.0.jar\n",
      "-> New file at /tmp/toree_add_deps1635466249893929454/https/repo1.maven.org/maven2/com/univocity/univocity-parsers/1.5.1/univocity-parsers-1.5.1.jar\n",
      "Starting download from file:lib/corenlp-models.jar\n",
      "Finished download of corenlp-models.jar\n",
      "Starting download from file:SE/target/scala-2.10/se_2.10-1.1.jar\n",
      "Finished download of se_2.10-1.1.jar\n"
     ]
    }
   ],
   "source": [
    "/* Add Deps */\n",
    "%AddDeps edu.stanford.nlp stanford-corenlp 3.7.0\n",
    "%AddDeps com.google.protobuf protobuf-java 2.6.1\n",
    "%AddDeps com.databricks spark-csv_2.10 1.5.0 --transitive\n",
    "\n",
    "// Non-repo dependencies \n",
    "%AddJar file:lib/corenlp-models.jar\n",
    "%AddJar file:SE/target/scala-2.10/se_2.10-1.1.jar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import com.evan.kaggle.se.FeatureEngineering._\n",
    "val sqlContext = org.apache.spark.sql.SQLContext.getOrCreate(sc)\n",
    "import sqlContext.implicits._\n",
    "import org.apache.spark.sql.functions._\n",
    "import org.apache.spark.sql.Row\n",
    "import scala.collection.immutable.HashSet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "val files = List(\"cooking\")//, \"crypto\", \"robotics\", \"biology\", \"travel\", \"diy\")\n",
    "\n",
    "/* Load and print all files */\n",
    "val df_all = files.map(f => {\n",
    "                        sqlContext.read.format(\"com.databricks.spark.csv\").option(\"header\", \"true\").load(\"../dat/\"+f+\"_clean.csv\")\n",
    "                   }).reduce(_ unionAll _).filter($\"content\" !== \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "val feat_udf = udf((t: String, c: String, ta: String) => \n",
    "    makeTrFeatures(3)(t, c, ta))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "val flat = df_all.select(explode(feat_udf($\"title\", $\"content\", $\"tags\")))\n",
    "val flat2 = flat.select($\"col.*\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 4237705 rows\n",
      "Elapsed: 699.17177708 seconds\n"
     ]
    }
   ],
   "source": [
    "val s = System.nanoTime\n",
    "println(s\"There are ${flat2.count} rows\")\n",
    "val diff = (System.nanoTime - s)/1e9d\n",
    "println(s\"Elapsed: $diff seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Apache Toree - Scala",
   "language": "scala",
   "name": "apache_toree_scala"
  },
  "language_info": {
   "name": "scala",
   "version": "2.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
