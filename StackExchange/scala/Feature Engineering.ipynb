{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Note: this nb is for demo purposes, the actual feature engineering is done in `com.evan.kaggle.se.FeatureEngineering`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Features:\n",
    "- `LEN`: number of words in tuple (ranges from 1 to 5)\n",
    "- `HAS_NN`: boolean indicating if the \n",
    "- `DEP_PATT`: string dependency pattern\n",
    "- `PREV_2_W`: previous 2 words\n",
    "- `NEXT_2_W`: next 2 words\n",
    "- `NEXT_W`: next word\n",
    "- `PREV_W`: next word\n",
    "- `PREV_2_T`: previous 2 tags\n",
    "- `NEXT_2_T`: next 2 tags\n",
    "- `NEXT_T`: next tag\n",
    "- `PREV_T`: prev tag\n",
    "- `DOC_FR`: document frequency\n",
    "- `IS_TITLE`: boolean indicating is this tuple from the title(true) or the post(false)\n",
    "- `REL_POS`: proportion of sentence preceding the first element of the tuple"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Marking edu.stanford.nlp:stanford-corenlp:3.7.0 for download\n",
      "Preparing to fetch from:\n",
      "-> file:/tmp/toree_add_deps7449986899999614546/\n",
      "-> https://repo1.maven.org/maven2\n",
      "-> New file at /tmp/toree_add_deps7449986899999614546/https/repo1.maven.org/maven2/edu/stanford/nlp/stanford-corenlp/3.7.0/stanford-corenlp-3.7.0.jar\n",
      "Marking com.google.protobuf:protobuf-java:2.6.1 for download\n",
      "Preparing to fetch from:\n",
      "-> file:/tmp/toree_add_deps7449986899999614546/\n",
      "-> https://repo1.maven.org/maven2\n",
      "-> New file at /tmp/toree_add_deps7449986899999614546/https/repo1.maven.org/maven2/com/google/protobuf/protobuf-java/2.6.1/protobuf-java-2.6.1.jar\n",
      "Starting download from file:lib/corenlp-models.jar\n",
      "Finished download of corenlp-models.jar\n"
     ]
    }
   ],
   "source": [
    "/* Add Deps */\n",
    "%AddDeps edu.stanford.nlp stanford-corenlp 3.7.0\n",
    "%AddDeps com.google.protobuf protobuf-java 2.6.1\n",
    "\n",
    "// Non-repo dependencies \n",
    "%AddJar file:lib/corenlp-models.jar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "/* Class Imports */\n",
    "import edu.stanford.nlp.simple.Sentence\n",
    "import edu.stanford.nlp.simple.Document\n",
    "import collection.JavaConverters._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Utility functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "code_folding": [],
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import scala.collection.mutable.ArrayBuffer\n",
    "def unzip4[A, B, C, D](in: List[(A, B, C, D)]): (List[A], List[B], List[C], List[D]) = \n",
    "{\n",
    "    val a_a = ArrayBuffer[A]()\n",
    "    val a_b = ArrayBuffer[B]()\n",
    "    val a_c = ArrayBuffer[C]()\n",
    "    val a_d = ArrayBuffer[D]()\n",
    "    for ((a,b,c,d) <- in)\n",
    "    {\n",
    "        a_a += a\n",
    "        a_b += b\n",
    "        a_c += c\n",
    "        a_d += d\n",
    "    }\n",
    "    (a_a.toList, a_b.toList, a_c.toList, a_d.toList)\n",
    "}\n",
    "\n",
    "/* Make n-grams from input list */\n",
    "/* TODO: use iterators to save conversion costs*/\n",
    "def mkNgram[A](n: Int, in: List[A]): List[List[A]] = \n",
    "{\n",
    "    in.sliding(n).map(_.toList).toList\n",
    "}\n",
    "\n",
    "/* LPDU is just a (lemma, hasUpper), dependency, part of speech, isUpper quad */\n",
    "case class LPDU(l: String, p: String, d: String, u:Boolean)\n",
    "\n",
    "/* Maps a sentence to a list of LPDU triples */\n",
    "def mkLPDUlist(s: Sentence): List[LPDU] = \n",
    "{\n",
    "    val l = s.lemmas\n",
    "    val p = s.posTags\n",
    "    val d = s.incomingDependencyLabels.asScala.map(_.get.toString)\n",
    "    val u = s.words.asScala.map(_.exists(_.isUpper))\n",
    "    \n",
    "    /* so imperative :( :( */\n",
    "    (for (i <- 0 until l.size if d(i) != \"punct\") \n",
    "        yield LPDU(l.get(i), p.get(i), d(i), u(i))) toList\n",
    "}\n",
    "\n",
    "/* \n",
    "    TODO: Think about  filters and implement them\n",
    "    The following is a set of filters to remove undesirable nrgram candidates:\n",
    "    - Ends with article (a/the)\n",
    "    - Starts or ends with a conjunction\n",
    "    - ???\n",
    "*/\n",
    "def ngramFilter(in: List[List[LPDU]]): List[List[LPDU]] =\n",
    "{\n",
    "    in\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "List(LPDU(this,DT,nsubj,true), LPDU(be,VBZ,cop,false), LPDU(a,DT,det,false), LPDU(test,NN,root,false))"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mkLPDUlist(new Sentence(\"This, is a test!\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Structure: \n",
    "\n",
    "For now I am implementing the following features:\n",
    "\n",
    "- posTags: String = string of - delimited pos tags for this ngram\n",
    "- depTags: String = string of - delimited dependency tags for this ngram\n",
    "- relPos: Double[0,1] = relative position of first element of the ngra,\n",
    "- numWords: Int = length of the ngram\n",
    "- hasUpper: contains uppercase char?\n",
    "- isTitle: Boolean = indicates if this\n",
    "- isTag: Boolean = target classification value, inidcates if this ngram is a tag\n",
    "\n",
    "These features will be represented in my `TrainingFeatures` and `StdFeatures` classes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "/* Simple struct representing training features */\n",
    "case class TrainingFeatures(nGram: String, posTags: String, depTags: String, relPos: Double,\n",
    "                            numWords: Int, hasUpper: Boolean, isTitle: Boolean, isTag: Boolean)\n",
    "\n",
    "/* Simple struct representing std features */\n",
    "case class StdFeatures(nGram: String, posTags: String, depTags: String, relPos: Double,\n",
    "                            numWords: Int, hasUpper: Boolean, isTitle: Boolean)\n",
    "                            \n",
    "/* Creates a TrainingFeatures instance from a StdFeatures instance */\n",
    "def mkTrFeat(s: StdFeatures, isTag: Boolean): TrainingFeatures = \n",
    "                TrainingFeatures(s.nGram, s.posTags, s.depTags, s.relPos, s.numWords,\n",
    "                                 s.hasUpper, s.isTitle, isTag)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Generation Steps\n",
    "- Get pos tags\n",
    "- Make `(lemma, dependency, part of speech)` triples\n",
    "- Make nGrams for n 1 through 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "def makeStdFeatures(n: Int)(title: String, content: String): Seq[StdFeatures] = \n",
    "{\n",
    "    // mk post sentence\n",
    "    val post_sents = (new Document(content)).sentences.asScala.toList\n",
    "    \n",
    "    // mk title sentence\n",
    "    val title_sents = (new Document(title)).sentences.asScala.toList\n",
    "    \n",
    "    // gather lemmas, pos tags, deps\n",
    "    // these features will be also be ngrammed \n",
    "    val post_feats: List[(List[LPDU], Boolean)] = post_sents.map(x => (mkLPDUlist(x), false))\n",
    "    val title_feats: List[(List[LPDU], Boolean)] = title_sents.map(x => (mkLPDUlist(x), true))\n",
    "    \n",
    "    /* N-Grammable features (plus isTitle)*/\n",
    "    val gram_feats_it: List[(List[LPDU], Boolean)] = post_feats ++ title_feats\n",
    "    \n",
    "    /* Loop over all ngram lengths */\n",
    "    (1 to n).flatMap{nGramLen => {\n",
    "        /* loop over all sentences in this post+title */\n",
    "        gram_feats_it.flatMap{ case (n_grammable: List[LPDU], isTitle: Boolean) => {\n",
    "            /* make n grams from n-grammable items */\n",
    "            val ngrams: List[List[LPDU]] = mkNgram(nGramLen, n_grammable)\n",
    "            \n",
    "            /* sentence length is the lenth of n_grammable*/\n",
    "            val senLen: Double = n_grammable.length.toDouble\n",
    "            \n",
    "            /* TODO: apply filters */\n",
    "            // val ngrams_good = ngramFilter(ngrams)\n",
    "            \n",
    "            /* Map ngrams to StdFeature */\n",
    "            ngrams.zipWithIndex.map{case (ngram: List[LPDU], index: Int) => {\n",
    "                /* Now we can calculate all of the std features: */\n",
    "                val lemmas = new StringBuffer()\n",
    "                val posTags = new StringBuffer() \n",
    "                val depTags = new StringBuffer()\n",
    "                var hasUpper = false\n",
    "                \n",
    "                for (i <- 0 until ngram.length)\n",
    "                {\n",
    "                    val lpdu = ngram(i)\n",
    "                    lemmas.append(lpdu.l)\n",
    "                    posTags.append(lpdu.p)\n",
    "                    depTags.append(lpdu.d)\n",
    "                    /* middle dependent \"-\" marks */\n",
    "                    if (i < ngram.length - 1)\n",
    "                    {\n",
    "                        lemmas.append(\"-\")\n",
    "                        posTags.append(\"-\")\n",
    "                        depTags.append(\"-\")\n",
    "                    }\n",
    "                    \n",
    "                    /* check if any upper case */\n",
    "                    hasUpper ||= lpdu.u\n",
    "                }\n",
    "                /* calc rest of feats */\n",
    "                val relPos = index / senLen\n",
    "                val numWords = nGramLen\n",
    "                StdFeatures(lemmas.toString, posTags.toString, depTags.toString,\n",
    "                            relPos, numWords, hasUpper, isTitle)\n",
    "            }}\n",
    "        }\n",
    "    }}}\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Vector(StdFeatures(be-a-title,VBZ-DT-NN,cop-det-root,0.25,3,false,true), StdFeatures(this-be-a,DT-VBZ-DT,nsubj-cop-det,0.0,3,true,true), StdFeatures(be-the-post,VBZ-DT-NN,cop-det-root,0.4,3,false,false), StdFeatures(this-be-the,DT-VBZ-DT,nsubj-cop-det,0.2,3,false,false), StdFeatures(while-this-be,IN-DT-VBZ,mark-nsubj-cop,0.0,3,true,false), StdFeatures(a-title,DT-NN,det-root,0.5,2,false,true), StdFeatures(be-a,VBZ-DT,cop-det,0.25,2,false,true), StdFeatures(this-be,DT-VBZ,nsubj-cop,0.0,2,true,true), StdFeatures(the-post,DT-NN,det-root,0.6,2,false,false), StdFeatures(be-the,VBZ-DT,cop-det,0.4,2,false,false), StdFeatures(this-be,DT-VBZ,nsubj-cop,0.2,2,false,false), StdFeatures(while-this,IN-DT,mark-nsubj,0.0,2,true,false), StdFeatures(title,NN,root,0.75,1,false,tr..."
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "makeStdFeatures(3)(\"This is a title.\", \"While this is the post.\").reverse"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Apache Toree - Scala",
   "language": "scala",
   "name": "apache_toree_scala"
  },
  "language_info": {
   "name": "scala",
   "version": "2.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
