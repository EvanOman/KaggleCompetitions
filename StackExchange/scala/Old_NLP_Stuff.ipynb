{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%AddDeps edu.stanford.nlp stanford-corenlp 3.6.0\n",
    "%AddDeps com.google.protobuf protobuf-java 2.6.1\n",
    "%AddDeps com.databricks spark-csv_2.10 1.4.0 --transitive\n",
    "%AddDeps net.sf.jwordnet jwnl 1.4_rc3 --transitive\n",
    "\n",
    "// Non-repo dependencies\" \n",
    "%AddJar file:lib/corenlp-models.jar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "2+2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import edu.stanford.nlp.semgraph.semgrex.SemgrexPattern\n",
    "import edu.stanford.nlp.simple.Sentence\n",
    "import org.apache.spark.sql._\n",
    "import scala.io.Source\n",
    "import org.apache.spark.sql.functions._\n",
    "val sqlContext = SQLContext.getOrCreate(sc)\n",
    "import sqlContext.implicits._\n",
    "import scala.collection.immutable.HashSet\n",
    "import edu.stanford.nlp.semgraph.SemanticGraph\n",
    "import java.io.File\n",
    "import org.apache.spark.sql.types._\n",
    "import edu.stanford.nlp.trees.UniversalEnglishGrammaticalRelations.{COMPOUND_MODIFIER, ADJECTIVAL_MODIFIER, NEGATION_MODIFIER, ADVERBIAL_MODIFIER}\n",
    "import collection.JavaConverters._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "code_folding": [
     23,
     118,
     141,
     142
    ],
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "val NEU = \"N\"\n",
    "val POS = \"+\"\n",
    "val NEG = \"-\"\n",
    "val UNK = \"?\"\n",
    "\n",
    "val positive = Source.fromFile(\"extraction_dat/positive.txt\").getLines.toList\n",
    "val negative = Source.fromFile(\"extraction_dat/negative.txt\").getLines.toList\n",
    "val neutral = Source.fromFile(\"extraction_dat/neutral.txt\").getLines.toList\n",
    "val nonfoods = Source.fromFile(\"extraction_dat/nonfoods.txt\").getLines.toList\n",
    "val pos_hash = HashSet(positive: _*)\n",
    "val neg_hash = HashSet(negative: _*)\n",
    "val neu_hash = HashSet(neutral: _*)\n",
    "val non_hash = HashSet(nonfoods: _*)\n",
    "\n",
    "/**** Pattern Broadcasting ****/\n",
    "/* \"x is y\" pattern */\n",
    "val x_is_y_pattern = Source.fromFile(\"rules/xiy.semgrex\").getLines.toList.head\n",
    "val xiyPatBr = sc.broadcast(SemgrexPattern.compile(x_is_y_pattern))\n",
    "/* \"good for\" pattern */\n",
    "val g4_pattern = Source.fromFile(\"rules/g4.semgrex\").getLines.toList.head\n",
    "val g4PatBr = sc.broadcast(SemgrexPattern.compile(g4_pattern))\n",
    "\n",
    "/**** Utilities ****/\n",
    "def cleanString(s: String): String =\n",
    "{\n",
    "    var sl = s\n",
    "\n",
    "    /* Remove non-ACII chars */\n",
    "    sl = sl.replaceAll(\"[^\\\\p{ASCII}]+\", \"\")\n",
    "\n",
    "    /* Space out scrunched words */\n",
    "    sl = sl.replaceAll(\"[\\\\.\\\\!\\\\?\\\\,\\\\;\\\\:]\", \" $0 \")\n",
    "\n",
    "    /* Infer period (this may not work well...) */\n",
    "    sl = sl.replaceAll(\"(\\\\p{Lower})(\\\\p{Upper})\", \"$1. $2\")\n",
    "\n",
    "    sl.toLowerCase\n",
    "}\n",
    "\n",
    "def applySentiment(adj: String): String =  if (pos_hash.contains(adj)) POS else if (neg_hash.contains(adj)) NEG else if (neu_hash.contains(adj)) NEU else UNK\n",
    "def reverseSent(s: String):String = if (s == POS || s == NEU) NEG else if (s == NEG) POS else s\n",
    "\n",
    "def pullAspect(g: SemanticGraph, node: edu.stanford.nlp.ling.IndexedWord): String =\n",
    "{\n",
    "    val mods = g.getChildrenWithRelns(node, List(COMPOUND_MODIFIER, ADJECTIVAL_MODIFIER).asJava).asScala.toList\n",
    "    var modStr = mods.map(_.word).mkString(\"_\")\n",
    "    modStr = if (modStr != \"\") modStr + \"_\" else \"\"\n",
    "    modStr + node.word\n",
    "}\n",
    "\n",
    "def pullAdjSentiment(g: SemanticGraph, node: edu.stanford.nlp.ling.IndexedWord): (String, String) =\n",
    "{\n",
    "    /*\n",
    "        Three cases:\n",
    "            - not_too X => Neutral\n",
    "            - too _ X => Negative\n",
    "            - not X => Opposite of X sentiment\n",
    "    */\n",
    "    var tooList = g.getChildren(node).asScala.toList\n",
    "    val too = if (tooList.size != 0) {var t = tooList.map(_.word).filter(_ == \"too\"); if (t.size != 0) t.head else \"\"} else \"\"\n",
    "    var negList = g.getChildrenWithReln(node, NEGATION_MODIFIER).asScala.toList\n",
    "    val neg = if (negList.size != 0) {var n = negList.map(_.word); if (n.size != 0) n.head else \"\"} else \"\"\n",
    "    val adj = node.word\n",
    "\n",
    "    if (too != \"\" && neg != \"\")\n",
    "    {\n",
    "        /* Sentiment is neutral */\n",
    "        val full_adj = neg + \"_\" + too + \"_\" + adj\n",
    "        var sent = applySentiment(full_adj)\n",
    "        sent = if (sent == UNK) NEU else sent\n",
    "        (full_adj, sent)\n",
    "    }\n",
    "    else if (too != \"\")\n",
    "    {\n",
    "        /* Sentiment is negative */\n",
    "        val full_adj = too + \"_\" + adj\n",
    "        var sent = applySentiment(full_adj)\n",
    "        sent = if (sent == UNK) NEG else sent\n",
    "        (full_adj, sent)\n",
    "    }\n",
    "    else if (neg != \"\")\n",
    "    {\n",
    "        /* Sentiment is the opposite of adj */\n",
    "        val full_adj = neg + \"_\" + adj\n",
    "        var sent = applySentiment(full_adj)\n",
    "        if (sent == UNK)\n",
    "        {\n",
    "            val sent_orig = applySentiment(adj)\n",
    "            sent = reverseSent(sent_orig) \n",
    "        }\n",
    "        (full_adj, sent)\n",
    "    }\n",
    "    else\n",
    "    {\n",
    "        /* vanilla case */\n",
    "        (adj, applySentiment(adj))\n",
    "    }\n",
    "}\n",
    "\n",
    "def extrXIYPattern(review: SemanticGraph): Vector[(String, String, String)] =\n",
    "{\n",
    "    var triples = Vector[(String, String, String)]()\n",
    "    val pattern = xiyPatBr.value\n",
    "    val matcher = pattern.matcher(review)\n",
    "    while (matcher.find)\n",
    "    {\n",
    "        val aspNode = matcher.getNode(\"aspect\")\n",
    "        if (!non_hash.contains(aspNode.word))\n",
    "        {\n",
    "            val adjNode = matcher.getNode(\"adj\")\n",
    "            val graph = matcher.getGraph\n",
    "            val aspect = pullAspect(graph, aspNode)\n",
    "            val adjSent = pullAdjSentiment(graph, adjNode)\n",
    "            triples = triples :+ (aspect, adjSent._1, adjSent._2)\n",
    "        }\n",
    "    }\n",
    "    triples\n",
    "}\n",
    "\n",
    "def extrG4Pattern(review: SemanticGraph): Vector[(String, String, String)] =\n",
    "{\n",
    "    var triples = Vector[(String, String, String)]()\n",
    "    val pattern = g4PatBr.value\n",
    "    val matcher = pattern.matcher(review)\n",
    "    while (matcher.find)\n",
    "    {\n",
    "        /* grab good vs great */\n",
    "        val adj = matcher.getNode(\"pos_jj\").word\n",
    "\n",
    "        /* grab comp and/or jj modifying the noun */\n",
    "        val aspNode = matcher.getNode(\"aspect\")\n",
    "        if (!non_hash.contains(aspNode.word))\n",
    "        {\n",
    "            val graph = matcher.getGraph\n",
    "            val aspect = pullAspect(graph, aspNode)\n",
    "            triples = triples :+ (aspect, adj, POS)\n",
    "        }\n",
    "    }\n",
    "    triples\n",
    "}\n",
    "\n",
    "/* Broadcasted list of pattern functions to apply to each review */\n",
    "val pattExtrBrs = sc.broadcast(Vector(extrXIYPattern _, extrG4Pattern _))\n",
    "\n",
    "/* Function which extracts all patterns from the given review */\n",
    "def extractPatterns(review: String): Vector[(String, String, String)] =\n",
    "{\n",
    "    if (review == null || review == \"\")\n",
    "    {\n",
    "        null\n",
    "    }\n",
    "    else\n",
    "    {\n",
    "        val sg: SemanticGraph = new Sentence(cleanString(review)).dependencyGraph\n",
    "        pattExtrBrs.value.flatMap(_(sg))\n",
    "    }\n",
    "}\n",
    "\n",
    "val ep_udf = udf(extractPatterns _)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Apache Toree - Scala",
   "language": "scala",
   "name": "apache_toree_scala"
  },
  "language_info": {
   "name": "scala",
   "version": "2.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
